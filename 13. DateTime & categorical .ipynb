{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e21956c0-b3dd-4a9a-a9bb-81911d0d7ded",
   "metadata": {},
   "source": [
    "# 13. first subtopic: `.dt accessor basics`.\n",
    "\n",
    "-----\n",
    "\n",
    "The `.dt` accessor is a special tool in Pandas that \"unlocks\" a large set of date and time properties and methods on a Series. You *cannot* use it on a regular `object` (text) column. You must *first* convert your column to the `datetime64[ns]` type using `pd.to_datetime()`.\n",
    "\n",
    "Think of a `datetime64` object as a locked box containing all the parts of a date (year, month, day, hour, etc.). The `.dt` accessor is the **key** to that box. Once you use it (e.g., `s.dt`), Pandas opens the box and gives you access to all the individual components, like `.dt.year`, `.dt.month`, and `.dt.day_name()`.\n",
    "\n",
    "**How It Works in Memory**: The `.dt` accessor itself doesn't store anything. It's a \"gateway\" or \"accessor\" object. When you call `s.dt.year`, Pandas is *not* storing a separate column of years. It's looking at the underlying `datetime64[ns]` data (which is just a single 64-bit integer for each date) and, on the fly, calculating the \"year\" component from that integer. This makes it very fast and memory-efficient.\n",
    "\n",
    "**When to Use This**: You *must* use this for **feature engineering**. It's the standard way to break a single date column into multiple useful pieces of information for analysis or machine learning models.\n",
    "\n",
    "  * Use `.dt.year` or `.dt.month` to **group by** time periods (e.g., `df.groupby(df['date'].dt.year).sum()`).\n",
    "  * Use `.dt.day_name()` or `.dt.hour` to **filter** for specific patterns (e.g., \"find all sales that happened on a weekend\" or \"during morning hours\").\n",
    "\n",
    "-----\n",
    "\n",
    "### 0\\. Syntax & Parameters (MUST COME FIRST)\n",
    "\n",
    "The `.dt` accessor is placed *between* your Series name and the property/method you want.\n",
    "\n",
    "```python\n",
    "# Accessing a PROPERTY (no parentheses)\n",
    "series.dt.property\n",
    "```\n",
    "\n",
    "  * **Properties:** `year`, `month`, `day`, `hour`, `minute`, `second`, `weekday`, `dayofyear`, `quarter`, etc.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "# Accessing a METHOD (with parentheses)\n",
    "series.dt.method()\n",
    "```\n",
    "\n",
    "  * **Methods:** `day_name()`, `month_name()`, `strftime()`, `normalize()`, `floor()`, `ceil()`, etc.\n",
    "\n",
    "**Key Point:** You can *only* use `.dt` on a Series that has a `dtype` of `datetime64[ns]` or `timedelta64[ns]`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. Basic Example (Accessing Properties)\n",
    "\n",
    "Let's convert a Series and access its basic parts.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s_dates = pd.Series(['2025-01-01', '2025-05-15', '2026-11-30'])\n",
    "\n",
    "# 1. We MUST convert it first\n",
    "s_dt = pd.to_datetime(s_dates)\n",
    "\n",
    "print(\"--- 1. Converted Series (datetime64[ns]) ---\")\n",
    "print(s_dt)\n",
    "\n",
    "# 2. Now, we can use the .dt accessor\n",
    "\n",
    "# Example 1: Get the year\n",
    "print(\"\\n--- 2. Example 1: .dt.year ---\")\n",
    "print(s_dt.dt.year)\n",
    "\n",
    "# Example 2: Get the month\n",
    "print(\"\\n--- 3. Example 2: .dt.month ---\")\n",
    "print(s_dt.dt.month)\n",
    "\n",
    "# Example 3: Get the day\n",
    "print(\"\\n--- 4. Example 3: .dt.day ---\")\n",
    "print(s_dt.dt.day)\n",
    "\n",
    "# Example 4: Get the day of the week (Mon=0, Sun=6)\n",
    "print(\"\\n--- 5. Example 4: .dt.weekday ---\")\n",
    "print(s_dt.dt.weekday)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 1. Converted Series (datetime64[ns]) ---\n",
    "0   2025-01-01\n",
    "1   2025-05-15\n",
    "2   2026-11-30\n",
    "dtype: datetime64[ns]\n",
    "\n",
    "--- 2. Example 1: .dt.year ---\n",
    "0    2025\n",
    "1    2025\n",
    "2    2026\n",
    "Name: year, dtype: int32\n",
    "\n",
    "--- 3. Example 2: .dt.month ---\n",
    "0     1\n",
    "1     5\n",
    "2    11\n",
    "Name: month, dtype: int32\n",
    "\n",
    "--- 4. Example 3: .dt.day ---\n",
    "0     1\n",
    "1    15\n",
    "2    30\n",
    "Name: day, dtype: int32\n",
    "\n",
    "--- 5. Example 4: .dt.weekday ---\n",
    "0    2\n",
    "1    3\n",
    "2    0\n",
    "Name: weekday, dtype: int32\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "As you can see, each `.dt.property` call returned a *new Series* containing just that part of the date. Note that `.dt.weekday` returned `2` (Wednesday), `3` (Thursday), and `0` (Monday).\n",
    "\n",
    "-----\n",
    "\n",
    "### 2\\. Intermediate Example (Accessing Methods)\n",
    "\n",
    "Methods (with `()`) give you more formatted or computed results.\n",
    "\n",
    "```python\n",
    "# Use the same s_dt from the previous example\n",
    "s_dt = pd.to_datetime(pd.Series(['2025-01-01', '2025-05-15', '2026-11-30']))\n",
    "\n",
    "# Example 5: Get the day's NAME\n",
    "print(\"\\n--- 6. Example 5: .dt.day_name() ---\")\n",
    "print(s_dt.dt.day_name())\n",
    "\n",
    "# Example 6: Get the month's NAME\n",
    "print(\"\\n--- 7. Example 6: .dt.month_name() ---\")\n",
    "print(s_dt.dt.month_name())\n",
    "\n",
    "# Example 7: Normalize (strip time information)\n",
    "s_time = pd.Series(['2025-01-01 08:30:00', '2025-05-15 12:00:00'])\n",
    "s_dt_time = pd.to_datetime(s_time)\n",
    "print(\"\\n--- 8. Example 7: Before .dt.normalize() ---\")\n",
    "print(s_dt_time)\n",
    "\n",
    "print(\"\\n--- 9. After .dt.normalize() ---\")\n",
    "print(s_dt_time.dt.normalize())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 6. Example 5: .dt.day_name() ---\n",
    "0     Wednesday\n",
    "1      Thursday\n",
    "2        Monday\n",
    "Name: day_name, dtype: object\n",
    "\n",
    "--- 7. Example 6: .dt.month_name() ---\n",
    "0     January\n",
    "1         May\n",
    "2    November\n",
    "Name: month_name, dtype: object\n",
    "\n",
    "--- 8. Example 7: Before .dt.normalize() ---\n",
    "0   2025-01-01 08:30:00\n",
    "1   2025-05-15 12:00:00\n",
    "dtype: datetime64[ns]\n",
    "\n",
    "--- 9. After .dt.normalize() ---\n",
    "0   2025-01-01\n",
    "1   2025-05-15\n",
    "dtype: datetime64[ns]\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "The methods `day_name()` and `month_name()` returned string representations. `.dt.normalize()` is a useful method to \"zero out\" the time, leaving just the date, which is great for grouping by day.\n",
    "\n",
    "-----\n",
    "\n",
    "### 3\\. Advanced or Tricky Case (Formatting & Filtering)\n",
    "\n",
    "This is where `.dt` becomes a powerful tool.\n",
    "\n",
    "**Example 8: `strftime()` for custom formats**\n",
    "`strftime` (string format time) lets you build any date string you want.\n",
    "\n",
    "```python\n",
    "# %Y = 4-digit year, %m = 2-digit month, %d = 2-digit day\n",
    "# %B = Full month name, %A = Full day name\n",
    "print(\"\\n--- 10. Example 8: .dt.strftime('%Y-%m') ---\")\n",
    "print(s_dt.dt.strftime('%Y-%m')) # Format as YYYY-MM\n",
    "\n",
    "print(\"\\n--- 11. Example 9: .dt.strftime (complex) ---\")\n",
    "print(s_dt.dt.strftime('%A, %B %d'))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 10. Example 8: .dt.strftime('%Y-%m') ---\n",
    "0    2025-01\n",
    "1    2025-05\n",
    "2    2026-11\n",
    "dtype: object\n",
    "\n",
    "--- 11. Example 9: .dt.strftime (complex) ---\n",
    "0    Wednesday, January 01\n",
    "1     Thursday, May 15\n",
    "2       Monday, November 30\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "`strftime` is a method that lets you *format* your dates back into strings, but in any custom format you want. This is great for reports.\n",
    "\n",
    "**Example 10: Filtering with `.dt`**\n",
    "This is the *real* power. You use the `.dt` accessor *inside* a boolean indexing mask.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'date': pd.to_datetime(['2025-01-15', '2025-02-10', '2025-03-05', '2025-04-30']),\n",
    "    'sales': [100, 150, 50, 200]\n",
    "})\n",
    "print(\"\\n--- 12. Original DataFrame ---\")\n",
    "print(df)\n",
    "\n",
    "# Example 11: Find all sales from February\n",
    "mask = df['date'].dt.month == 2\n",
    "print(\"\\n--- 13. Example 11: Sales from February ---\")\n",
    "print(df[mask])\n",
    "\n",
    "# Example 12: Find all sales from the first half of the month\n",
    "mask2 = df['date'].dt.day <= 15\n",
    "print(\"\\n--- 14. Example 12: Sales from 1st-15th ---\")\n",
    "print(df[mask2])\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 12. Original DataFrame ---\n",
    "        date  sales\n",
    "0 2025-01-15    100\n",
    "1 2025-02-10    150\n",
    "2 2025-03-05     50\n",
    "3 2025-04-30    200\n",
    "\n",
    "--- 13. Example 11: Sales from February ---\n",
    "        date  sales\n",
    "1 2025-02-10    150\n",
    "\n",
    "--- 14. Example 12: Sales from 1st-15th ---\n",
    "        date  sales\n",
    "0 2025-01-15    100\n",
    "1 2025-02-10    150\n",
    "2 2025-03-05     50\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### 4\\. Real-World Use Case (Feature Engineering)\n",
    "\n",
    "This is the \\#1 use case for the `.dt` accessor. You take a *single* date column and create *many* new \"feature\" columns to help a machine learning model find patterns.\n",
    "\n",
    "**Example 13: Create multiple features**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'timestamp': pd.to_datetime(['2025-11-17 08:30:00', '2025-11-18 12:15:00'])\n",
    "})\n",
    "print(\"\\n--- 15. Original DataFrame ---\")\n",
    "print(df)\n",
    "\n",
    "# Example 14: Create 'month', 'weekday', and 'hour' features\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df['weekday'] = df['timestamp'].dt.day_name()\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['is_weekend'] = df['timestamp'].dt.weekday >= 5 # (Mon=0... Sat=5, Sun=6)\n",
    "\n",
    "print(\"\\n--- 16. Example 14: DataFrame with new features ---\")\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 15. Original DataFrame ---\n",
    "            timestamp\n",
    "0 2025-11-17 08:30:00\n",
    "1 2025-11-18 12:15:00\n",
    "\n",
    "--- 16. Example 14: DataFrame with new features ---\n",
    "            timestamp  month    weekday  hour  is_weekend\n",
    "0 2025-11-17 08:30:00     11     Monday     8       False\n",
    "1 2025-11-18 12:15:00     11    Tuesday    12       False\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "We started with just one `timestamp` column. From it, we \"engineered\" four new columns (`month`, `weekday`, `hour`, `is_weekend`) that can be fed to a model. A model can't understand `'2025-11-17 08:30:00'`, but it *can* understand `month=11`, `hour=8`, and `is_weekend=False`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 5\\. Common Mistakes / Pitfalls\n",
    "\n",
    "**Mistake 15: `AttributeError: Can only use .dt accessor...`**\n",
    "This is the \\#1 error. You forgot to convert the column first.\n",
    "\n",
    "```python\n",
    "s_text = pd.Series(['2025-01-01'])\n",
    "print(\"\\n--- 17. Series is 'object' type ---\")\n",
    "print(f\"Dtype: {s_text.dtype}\")\n",
    "\n",
    "# Wrong code\n",
    "try:\n",
    "    s_text.dt.year\n",
    "except AttributeError as e:\n",
    "    print(f\"\\n--- 18. Error ---\")\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "`AttributeError: Can only use .dt accessor with datetimelike values`\n",
    "**Why it happens:** The column `s_text` is `object` (text). Pandas doesn't know it's a date.\n",
    "**Example 19: Corrected code:**\n",
    "You *must* convert it first.\n",
    "\n",
    "```python\n",
    "s_dt = pd.to_datetime(s_text)\n",
    "print(\"\\n--- 19. Corrected ---\")\n",
    "print(s_dt.dt.year)\n",
    "```\n",
    "\n",
    "**Mistake 20: Forgetting `.dt`**\n",
    "This is a very common beginner mistake.\n",
    "\n",
    "```python\n",
    "s_dt = pd.to_datetime(pd.Series(['2025-01-01']))\n",
    "print(\"\\n--- 20. Series is datetime ---\")\n",
    "print(f\"Dtype: {s_dt.dtype}\")\n",
    "\n",
    "# Wrong code\n",
    "try:\n",
    "    s_dt.year\n",
    "except AttributeError as e:\n",
    "    print(f\"\\n--- 21. Error ---\")\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "`AttributeError: 'Series' object has no attribute 'year'`\n",
    "**Why it happens:** The `Series` object itself doesn't have a `.year` property. The *accessor* has the property.\n",
    "**Example 21: Corrected code:**\n",
    "You have to put `.dt` in the middle.\n",
    "\n",
    "```python\n",
    "print(\"\\n--- 22. Corrected ---\")\n",
    "print(s_dt.dt.year)\n",
    "```\n",
    "\n",
    "# DateTime & categorical  `pd.Categorical()` and the \"category\" dtype.\n",
    "\n",
    "-----\n",
    "\n",
    "The **category** data type is a special, high-performance type in Pandas. It is a memory-saving \"specialist\" for columns that have a *limited number* of *repeating string values*.\n",
    "\n",
    "Think of a column like \"Gender\" (`['Male', 'Female', 'Male', 'Male']...`). Instead of storing the full text string \"Male\" thousands of times, Pandas can use the `category` type to store \"Male\" and \"Female\" *once*, and then use tiny integers (like `0` and `1`) behind the scenes to represent the full column. This can save a massive amount of memory (often 90%+) and also speed up operations like `groupby`.\n",
    "\n",
    "`pd.Categorical()` is the underlying *constructor* that creates this structure. However, in practice, you will almost always use the shortcut: `df['col'].astype('category')`.\n",
    "\n",
    "**How It Works in Memory**: A `category` column is split into two parts:\n",
    "\n",
    "1.  **`categories`**: An index of the *unique* values (e.g., `['Female', 'Male']`).\n",
    "2.  **`codes`**: A column of *integers* (e.g., `[0, 1, 0, 0]`) that map to the `categories`.\n",
    "\n",
    "This is why it's so efficient. Storing thousands of `int`s is much, much cheaper than storing thousands of full-text strings.\n",
    "\n",
    "**When to Use This**:\n",
    "\n",
    "  * **This is a critical optimization.** You should *always* use this on text (`object`) columns that have low cardinality (i.e., few unique values compared to the total size).\n",
    "  * **Good candidates:** \"State\", \"Country\", \"Gender\", \"Status\" (e.g., \"Pending\", \"Complete\"), \"Department\", \"SKU\".\n",
    "  * **Bad candidates:** \"Full Name\", \"Email Address\", \"Comment Text\" (these are all unique and won't save any memory).\n",
    "  * Use `pd.Categorical()` (the constructor) when you need to *pre-define* the categories and their order (e.g., \"Low\", \"Medium\", \"High\").\n",
    "\n",
    "-----\n",
    "\n",
    "### 0\\. Syntax & Parameters (MUST COME FIRST)\n",
    "\n",
    "There are two ways to create a categorical type.\n",
    "\n",
    "#### 1\\. The Easy Way: `series.astype('category')`\n",
    "\n",
    "This is what you will use 99% of the time.\n",
    "\n",
    "```python\n",
    "series.astype('category')\n",
    "```\n",
    "\n",
    "  * **What it does:** Converts an existing Series (usually `object` type) to `category` type. Pandas will automatically find the unique values.\n",
    "\n",
    "#### 2\\. The Powerful Way: `pandas.Categorical()`\n",
    "\n",
    "This is the \"constructor\" you use when you need more control, like setting a specific *order*.\n",
    "\n",
    "```python\n",
    "pandas.Categorical(values, categories=None, ordered=False)\n",
    "```\n",
    "\n",
    "  * **`values`**\n",
    "      * **What it does:** The raw data (a list, Series, etc.) that you want to convert.\n",
    "      * **Default value:** (Required)\n",
    "      * **When you would use it:** You *always* provide this. `pd.Categorical(['A', 'B', 'A'])`.\n",
    "  * **`categories`**\n",
    "      * **What it does:** An \"allow list\" of the *only* categories that are valid. If you provide this, any value in `values` that is *not* in this list will be converted to `NaN`.\n",
    "      * **Default value:** `None`\n",
    "      * **When you would use it:** To enforce data quality or set a specific order. `categories=['Low', 'Medium', 'High']`.\n",
    "      * **What happens if you don't specify it:** Pandas infers the categories from the `values` (e.g., `['A', 'B']`).\n",
    "  * **`ordered`**\n",
    "      * **What it does:** A boolean (True/False). If `True`, it tells Pandas that the categories have a *meaningful order* (e.g., \"Low\" \\< \"Medium\" \\< \"High\").\n",
    "      * **Default value:** `False`\n",
    "      * **When you would use it:** You *must* set this to `True` if you are creating an ordinal (ordered) category. This \"unlocks\" sorting and min/max operations.\n",
    "      * **What happens if you don't specify it:** The categories are treated as unordered (e.g., \"Male\" is not \\> \"Female\").\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. Basic Example\n",
    "\n",
    "Let's see the 99% use case: `.astype('category')`.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example 1: Original 'object' Series\n",
    "# A column of 1 million rows, but only 3 unique values\n",
    "s_object = pd.Series(['A', 'B', 'C', 'A'] * 250000)\n",
    "print(\"--- 1. Original (object) ---\")\n",
    "print(s_object.head())\n",
    "print(f\"Dtype: {s_object.dtype}\")\n",
    "print(f\"Memory: {s_object.memory_usage(deep=True)} bytes\")\n",
    "\n",
    "# Example 2: Converted 'category' Series\n",
    "s_cat = s_object.astype('category')\n",
    "print(\"\\n--- 2. Converted (category) ---\")\n",
    "print(s_cat.head())\n",
    "print(f\"Dtype: {s_cat.dtype}\")\n",
    "print(f\"Memory: {s_cat.memory_usage(deep=True)} bytes\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 1. Original (object) ---\n",
    "0    A\n",
    "1    B\n",
    "2    C\n",
    "3    A\n",
    "dtype: object\n",
    "Dtype: object\n",
    "Memory: 60000128 bytes\n",
    "\n",
    "--- 2. Converted (category) ---\n",
    "0    A\n",
    "1    B\n",
    "2    C\n",
    "3    A\n",
    "dtype: category\n",
    "Categories (3, object): ['A', 'B', 'C']\n",
    "Dtype: category\n",
    "Memory: 1000332 bytes\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Look at the memory usage\\! We went from \\~60 MB to \\~1 MB. This is a 98% memory saving. Pandas automatically found the 3 unique \"Categories\" (`['A', 'B', 'C']`) and converted the 1 million strings into 1 million small integers.\n",
    "\n",
    "**Example 3: Using the `.cat` accessor**\n",
    "Just like `.dt` for dates, `category` columns unlock the `.cat` accessor.\n",
    "\n",
    "```python\n",
    "# 's_cat' is our Series from Example 2\n",
    "# Example 4: Get the categories\n",
    "print(\"\\n--- 3. .cat.categories ---\")\n",
    "print(s_cat.cat.categories)\n",
    "\n",
    "# Example 5: Get the underlying integer codes\n",
    "print(\"\\n--- 4. .cat.codes (showing first 5) ---\")\n",
    "print(s_cat.cat.codes.head())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 3. .cat.categories ---\n",
    "Index(['A', 'B', 'C'], dtype='object')\n",
    "\n",
    "--- 4. .cat.codes (showing first 5) ---\n",
    "0    0\n",
    "1    1\n",
    "2    2\n",
    "3    0\n",
    "4    1\n",
    "dtype: int8\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "This shows how it works. It stores `['A', 'B', 'C']` *once*, and the data `['A', 'B', 'C', 'A', 'B']` is stored as `[0, 1, 2, 0, 1]`...\n",
    "\n",
    "-----\n",
    "\n",
    "### 2\\. Intermediate Example\n",
    "\n",
    "Using `pd.Categorical()` to create an **ordered** category. This is the \"powerful\" way.\n",
    "\n",
    "**Example 6: Creating an *ordered* category**\n",
    "This is for data where the order *matters* (e.g., 'Low' \\< 'Medium' \\< 'High').\n",
    "\n",
    "```python\n",
    "# The data, in a random order\n",
    "data = ['Medium', 'Low', 'High', 'Low', 'Medium']\n",
    "\n",
    "# Example 7: Define the *correct* order\n",
    "level_order = ['Low', 'Medium', 'High']\n",
    "\n",
    "# Create the categorical\n",
    "s_ordered = pd.Categorical(data, categories=level_order, ordered=True)\n",
    "s_ordered = pd.Series(s_ordered) # Put it back in a Series for easy viewing\n",
    "\n",
    "print(\"--- 5. Ordered Category ---\")\n",
    "print(s_ordered)\n",
    "print(f\"\\nIs it ordered? {s_ordered.cat.ordered}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 5. Ordered Category ---\n",
    "0    Medium\n",
    "1       Low\n",
    "2      High\n",
    "3       Low\n",
    "4    Medium\n",
    "dtype: category\n",
    "Categories (3, object): ['Low' < 'Medium' < 'High']\n",
    "\n",
    "Is it ordered? True\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "By setting `ordered=True` and providing the `categories` list, we've \"taught\" Pandas the correct order. The output `['Low' < 'Medium' < 'High']` shows this.\n",
    "\n",
    "**Example 8: Why an ordered category is powerful**\n",
    "Now we can sort *logically*, not alphabetically.\n",
    "\n",
    "```python\n",
    "# Use the ordered Series from Example 7\n",
    "print(\"\\n--- 6. Logical Sorting ---\")\n",
    "print(s_ordered.sort_values())\n",
    "\n",
    "# Example 9: We can also filter using < or >\n",
    "print(\"\\n--- 7. Logical Filtering (> 'Low') ---\")\n",
    "print(s_ordered[s_ordered > 'Low'])\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 6. Logical Sorting ---\n",
    "1       Low\n",
    "3       Low\n",
    "0    Medium\n",
    "4    Medium\n",
    "2      High\n",
    "dtype: category\n",
    "Categories (3, object): ['Low' < 'Medium' < 'High']\n",
    "\n",
    "--- 7. Logical Filtering (> 'Low') ---\n",
    "0    Medium\n",
    "2      High\n",
    "4    Medium\n",
    "dtype: category\n",
    "Categories (3, object): ['Low' < 'Medium' < 'High']\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "  * A normal sort (`.sort_values()`) on \"High\", \"Low\", \"Medium\" would be alphabetical (\"High\", \"Low\", \"Medium\").\n",
    "  * Because our category is *ordered*, `sort_values()` correctly puts \"Low\" first.\n",
    "  * We can also now use logical filters like `> 'Low'`, which is impossible with `object` strings.\n",
    "\n",
    "-----\n",
    "\n",
    "### 3\\. Advanced or Tricky Case\n",
    "\n",
    "Using `categories` to enforce data quality and finding values that aren't in the list.\n",
    "\n",
    "**Example 10: Using `categories` as a \"validator\"**\n",
    "What happens if our data has a typo?\n",
    "\n",
    "```python\n",
    "data = ['A', 'B', 'C', 'D'] # 'D' is a typo\n",
    "allowed_cats = ['A', 'B', 'C']\n",
    "\n",
    "# Example 11: Create a categorical, defining the *only* allowed categories\n",
    "s_validated = pd.Categorical(data, categories=allowed_cats)\n",
    "s_validated = pd.Series(s_validated)\n",
    "\n",
    "print(\"--- 8. Validated Category ---\")\n",
    "print(s_validated)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 8. Validated Category ---\n",
    "0      A\n",
    "1      B\n",
    "2      C\n",
    "3    NaN\n",
    "dtype: category\n",
    "Categories (3, object): ['A', 'B', 'C']\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "We defined the `categories` as `['A', 'B', 'C']`. When `pd.Categorical` saw `'D'` in the `data`, it did *not* know what to do with it, so it converted it to `NaN`. This is a powerful way to clean data and enforce a \"schema.\"\n",
    "\n",
    "**Example 12: Adding a new category**\n",
    "What if you need to add a new *valid* category after creation?\n",
    "\n",
    "```python\n",
    "s_cat = pd.Series(['A', 'B']).astype('category')\n",
    "print(\"\\n--- 9. Before ---\")\n",
    "print(s_cat.cat.categories)\n",
    "\n",
    "# This will add 'C' to the list of known categories\n",
    "s_cat_new = s_cat.cat.add_categories(['C'])\n",
    "print(\"\\n--- 10. After .cat.add_categories() ---\")\n",
    "print(s_cat_new.cat.categories)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 9. Before ---\n",
    "Index(['A', 'B'], dtype='object')\n",
    "\n",
    "--- 10. After .cat.add_categories() ---\n",
    "Index(['A', 'B', 'C'], dtype='object')\n",
    "```\n",
    "\n",
    "**Example 13: Removing a category**\n",
    "\n",
    "```python\n",
    "# Example 14: Removing 'B'\n",
    "s_cat_removed = s_cat.cat.remove_categories(['B'])\n",
    "print(\"\\n--- 11. After .cat.remove_categories() ---\")\n",
    "print(s_cat_removed.cat.categories)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 11. After .cat.remove_categories() ---\n",
    "Index(['A'], dtype='object')\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### 4\\. Real-World Use Case\n",
    "\n",
    "**Example 15: Cleaning and ordering a \"Survey\" column**\n",
    "You have survey data with \"ratings\" as text. You want to clean, order, and analyze it.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'user': [1, 2, 3, 4, 5],\n",
    "    'rating': ['Good', 'OK', 'Bad', 'OK', 'Godo'] # 'Godo' is a typo\n",
    "})\n",
    "print(\"--- 12. Original Survey Data ---\")\n",
    "print(df)\n",
    "\n",
    "# Example 16: Define the order and clean\n",
    "# 1. Define the correct, ordered categories\n",
    "rating_order = ['Bad', 'OK', 'Good']\n",
    "\n",
    "# 2. Convert using pd.Categorical to validate\n",
    "# This turns 'Godo' into NaT\n",
    "df['rating_cat'] = pd.Categorical(df['rating'], categories=rating_order, ordered=True)\n",
    "\n",
    "print(\"\\n--- 13. Cleaned and Ordered ---\")\n",
    "print(df)\n",
    "df.info()\n",
    "\n",
    "# Example 17: Now we can analyze\n",
    "print(\"\\n--- 14. Find all users who rated > 'Bad' ---\")\n",
    "print(df[df['rating_cat'] > 'Bad'])\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 12. Original Survey Data ---\n",
    "   user rating\n",
    "0     1   Good\n",
    "1     2     OK\n",
    "2     3    Bad\n",
    "3     4     OK\n",
    "4     5   Godo\n",
    "\n",
    "--- 13. Cleaned and Ordered ---\n",
    "   user rating rating_cat\n",
    "0     1   Good       Good\n",
    "1     2     OK         OK\n",
    "2     3    Bad        Bad\n",
    "3     4     OK         OK\n",
    "4     5   Godo        NaN\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 5 entries, 0 to 4\n",
    "Data columns (total 3 columns):\n",
    " #   Column      Non-Null Count  Dtype   \n",
    "---  ------      --------------  -----   \n",
    " 0   user        5 non-null      int64   \n",
    " 1   rating      5 non-null      object  \n",
    " 2   rating_cat  4 non-null      category\n",
    "dtypes: category(1), int64(1), object(1)\n",
    "memory usage: 325.0 bytes\n",
    "\n",
    "--- 14. Find all users who rated > 'Bad' ---\n",
    "   user rating rating_cat\n",
    "0     1   Good       Good\n",
    "1     2     OK         OK\n",
    "3     4     OK         OK\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "This is a perfect workflow. We used `pd.Categorical` to:\n",
    "\n",
    "1.  **Clean** the data (the typo `'Godo'` became `NaN`).\n",
    "2.  **Order** the data (`'Bad' < 'OK' < 'Good'`).\n",
    "3.  **Enable** powerful filtering (like `df['rating_cat'] > 'Bad'`).\n",
    "\n",
    "-----\n",
    "\n",
    "### 5\\. Common Mistakes / Pitfalls\n",
    "\n",
    "**Mistake 18: Using `category` on a high-cardinality column**\n",
    "\"Cardinality\" means \"number of unique values.\"\n",
    "\n",
    "```python\n",
    "# Wrong code (bad idea)\n",
    "s_email = pd.Series(['a@test.com', 'b@test.com', 'c@test.com', ...])\n",
    "print(\"\\n--- 15. High Cardinality (e.g., email) ---\")\n",
    "print(f\"Memory (object): {s_email.memory_usage(deep=True)} bytes\")\n",
    "\n",
    "s_email_cat = s_email.astype('category')\n",
    "print(\"\\n--- 16. As category (BAD) ---\")\n",
    "print(f\"Memory (category): {s_email_cat.memory_usage(deep=True)} bytes\")\n",
    "```\n",
    "\n",
    "**Why it happens:** If almost *every* value is unique (like an email or a unique ID), the `category` type has to store *all* of them in the `categories` index *plus* the `codes`\\! This often uses *more* memory than just leaving it as `object`.\n",
    "**Rule of thumb:** `category` is good when `df['col'].nunique() / len(df)` is very low (e.g., \\< 1%).\n",
    "\n",
    "**Mistake 19: Trying to set a value that isn't a known category**\n",
    "\n",
    "```python\n",
    "s_cat = pd.Series(['A', 'B']).astype('category')\n",
    "print(\"\\n--- 17. Original Categories ---\")\n",
    "print(s_cat.cat.categories)\n",
    "\n",
    "# Wrong code\n",
    "try:\n",
    "    s_cat.loc[2] = 'C' # 'C' is not in ['A', 'B']\n",
    "except TypeError as e:\n",
    "    print(f\"\\n--- 18. Error ---\")\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "`TypeError: cannot set item on a Categorical with a new category...`\n",
    "**Why it happens:** This is a safety feature. The column *only* knows about 'A' and 'B'.\n",
    "**Example 20: Corrected code:**\n",
    "You *must* add the category *first*.\n",
    "\n",
    "```python\n",
    "s_cat_new = s_cat.cat.add_categories(['C'])\n",
    "s_cat_new.loc[2] = 'C' # Now this works\n",
    "print(\"\\n--- 19. Corrected ---\")\n",
    "print(s_cat_new)\n",
    "```\n",
    "\n",
    "**Mistake 21: Forgetting `ordered=True`**\n",
    "\n",
    "```python\n",
    "# Wrong code\n",
    "s_unordered = pd.Series(['Low', 'Medium', 'High']).astype('category')\n",
    "print(\"\\n--- 20. Unordered Category ---\")\n",
    "try:\n",
    "    print(s_unordered.min()) # Fails on unordered\n",
    "except TypeError as e:\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "`Categorical is not ordered...`\n",
    "**Why it happens:** You didn't tell Pandas the order. It has no idea if \"Low\" is smaller than \"High\".\n",
    "**Correction:** You *must* use `pd.Categorical(..., ordered=True)` for `min()`, `max()`, or `<`/`>` to work.\n",
    "\n",
    "---- \n",
    "\n",
    "\n",
    "Here are the combined remaining sections for **.dt accessor** and **pd.Categorical()**.\n",
    "\n",
    "-----\n",
    "\n",
    "### 6\\. Key Terms (Explained Simply)\n",
    "\n",
    "  * **`.dt` Accessor:** A \"gateway\" property on a `datetime64[ns]` Series that \"unlocks\" date and time properties (like `.dt.year`, `.dt.day_name()`).\n",
    "  * **`datetime64[ns]`:** The data type for a date/time column in Pandas. You *must* have this type before you can use `.dt`.\n",
    "  * **Feature Engineering:** The process of creating new, useful columns (features) from your raw data, often by using `.dt` (e.g., creating `.dt.month`, `.dt.weekday`).\n",
    "  * **`category` (dtype):** A memory-saving data type for columns with few unique, repeated values (e.g., 'Male'/'Female').\n",
    "  * **`pd.Categorical()`:** The \"constructor\" used to build a categorical column, especially when you need to define a specific *order* (`ordered=True`).\n",
    "  * **`.cat` Accessor:** A \"gateway\" property on a `category` Series that \"unlocks\" its special properties (like `.cat.categories`, `.cat.codes`).\n",
    "  * **Cardinality:** The number of unique values in a column. `category` type is best for **low-cardinality** columns (e.g., 'State', not 'Email').\n",
    "  * **Ordinal:** A category with a meaningful order (e.g., 'Low' \\< 'Medium' \\< 'High'). Created by setting `ordered=True`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 7\\. Best Practices\n",
    "\n",
    "  * **For `.dt`:**\n",
    "      * **Convert first:** Always use `pd.to_datetime()` *before* you try to use `.dt`.\n",
    "      * **Vectorize:** Use `.dt` properties to filter or create new columns.\n",
    "          * **Good:** `df[df['date'].dt.weekday > 4]`\n",
    "          * **Bad:** `for row in df.index: if row.date().weekday() > 4...` (This is thousands of times slower).\n",
    "      * **Feature Engineer:** Don't hesitate to break a date into many `.dt` columns (`year`, `month`, `weekday`) for analysis.\n",
    "  * **For `category`:**\n",
    "      * **Check `nunique()`:** Before converting, check `df['col'].nunique()`. If it's very high (like 'Email'), *do not* use `category`.\n",
    "      * **Use on low-cardinality `object`:** Always use `s.astype('category')` on columns like 'State', 'Gender', 'Status', 'Region' to save memory.\n",
    "      * **Use `pd.Categorical()` for ordering:** If your category has a logical order ('Bad' \\< 'Good'), use the full `pd.Categorical(..., ordered=True)` constructor to set it.\n",
    "      * **Add categories first:** If you need to add a new value (like 'C') to a category column that only knows 'A' and 'B', you must use `s.cat.add_categories(['C'])` *before* you can set the value.\n",
    "\n",
    "-----\n",
    "\n",
    "### 8\\. Mini Summary\n",
    "\n",
    "  * **`.dt` accessor** is the key (`.dt.`) that unlocks properties (`.year`, `.month`) and methods (`.day_name()`) on a `datetime64[ns]` Series.\n",
    "  * You *must* convert text to `datetime64[ns]` using `pd.to_datetime()` *before* you can use `.dt`.\n",
    "  * **`category` dtype** is a massive memory-saver for text columns with few unique values (low cardinality).\n",
    "  * Use `s.astype('category')` for a quick, unordered conversion.\n",
    "  * Use `pd.Categorical(..., ordered=True)` to create *ordered* categories (like 'Low', 'Medium', 'High') that can be sorted logically.\n",
    "  * `category` columns have a `.cat` accessor for tasks like adding/removing categories.\n",
    "\n",
    "-----\n",
    "\n",
    "### 10\\. Practice Tasks\n",
    "\n",
    "**Data for Tasks:**\n",
    "\n",
    "```python\n",
    "df_practice = pd.DataFrame({\n",
    "    'timestamp': ['2025-01-01 10:00', '2025-01-31 22:00', '2025-02-15 05:00', '2025-02-16 12:00'],\n",
    "    'user_level': ['Gold', 'Silver', 'Bronze', 'Silver'],\n",
    "    'sales': [100, 50, 20, 55]\n",
    "})\n",
    "```\n",
    "\n",
    "**Task 24 (Easy - `.dt`):**\n",
    "First, convert the 'timestamp' column in `df_practice` to `datetime64[ns]`. Then, use the `.dt` accessor to create a new column called 'Hour' that contains just the hour (10, 22, 5, 12).\n",
    "\n",
    "**Task 25 (Medium - `category`):**\n",
    "The 'user\\_level' column is a perfect candidate for `category` type. Create a new DataFrame `df_medium` where 'user\\_level' is converted to a category. Then, print the *memory usage* of the original `df_practice['user_level']` and the new `df_medium['user_level']`.\n",
    "\n",
    "**Task 26 (Hard - both):**\n",
    "Using `df_practice`, create an \"analysis DataFrame\" that shows:\n",
    "\n",
    "1.  A new column 'day\\_name' (e.g., 'Wednesday') from the 'timestamp' column.\n",
    "2.  The 'user\\_level' column has been converted into an *ordered* category with the logical order `['Bronze', 'Silver', 'Gold']`.\n",
    "3.  Filter this new DataFrame to show only sales that occurred on a 'day\\_name' *after* 'Monday' (using `.dt.weekday`) and had a 'user\\_level' *greater than* 'Bronze'.\n",
    "\n",
    "-----\n",
    "\n",
    "### 11\\. Recommended Next Topic\n",
    "\n",
    "You've learned how to convert and work with the most important data types. The next logical step from the roadmap is to focus on a new data-cleaning task: finding and handling \"bad\" data beyond just `NaN`s.\n",
    "\n",
    "[cite\\_start]**Recommended:** **Handling Missing Data (re-visited) & Duplicates (`.isna()`, `.dropna()`, `.fillna()`, `.duplicated()`, `.drop_duplicates()`)** [cite: 42-45, 51-53]\n",
    "\n",
    "-----\n",
    "\n",
    "### 12\\. Quick Reference Card\n",
    "\n",
    "| Accessor | Data Type | Syntax | Example Properties / Methods |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **`.dt`** | `datetime64[ns]` | `series.dt.property` | `.dt.year`, `.dt.month`, `.dt.day`, `.dt.hour`, `.dt.weekday` |\n",
    "| | (dates/times) | `series.dt.method()` | `.dt.day_name()`, `.dt.month_name()`, `.dt.normalize()`, `.dt.strftime()` |\n",
    "| **`.cat`** | `category` | `series.cat.property` | `.cat.categories`, `.cat.codes`, `.cat.ordered` |\n",
    "| | (categorical) | `series.cat.method()` | `.cat.add_categories()`, `.cat.remove_categories()`, `.cat.set_categories()` |\n",
    "| **To Create** | `object` -\\> `datetime` | `pd.to_datetime(series)` | (Use `format` and `errors='coerce'`) |\n",
    "| **To Create** | `object` -\\> `category` | `series.astype('category')` | (Fastest, unordered) |\n",
    "| **To Create** | `object` -\\> `category` | `pd.Categorical(series, ...)` | (Use for `ordered=True`) |\n",
    "\n",
    "-----\n",
    "\n",
    "### 13\\. Common Interview Questions\n",
    "\n",
    "1.  **I have a 'date' column as `object`. Why can't I use `df['date'].dt.year`?**\n",
    "      * The `.dt` accessor *only* works on a column that is already a `datetime64[ns]` type. You must first convert it using `df['date'] = pd.to_datetime(df['date'])`.\n",
    "2.  **I have a column of 5 million rows for \"State\". `df.info()` shows it's using 400MB of memory. How can I fix this?**\n",
    "      * Convert it to a `category` type: `df['State'] = df['State'].astype('category')`. Since there are only \\~50 unique states, Pandas will store the 50 names once and use small integers for the 5 million rows, drastically reducing memory usage.\n",
    "3.  **How do you create a 'Survey' column where \"Bad\" \\< \"OK\" \\< \"Good\"?**\n",
    "      * You can't use `.astype('category')`, as that will be unordered.\n",
    "      * You must use the `pd.Categorical` constructor:\n",
    "      * `order = ['Bad', 'OK', 'Good']`\n",
    "      * `df['Survey_Cat'] = pd.Categorical(df['Survey_Raw'], categories=order, ordered=True)`\n",
    "4.  **How do you find all sales that happened on a weekend?**\n",
    "      * First, ensure your date column is `datetime64[ns]`.\n",
    "      * Then, use the `.dt.weekday` property. The weekday accessor returns Monday=0, Sunday=6.\n",
    "      * `df_weekends = df[df['date'].dt.weekday >= 5]`\n",
    "\n",
    "-----\n",
    "\n",
    "### 14\\. Performance Considerations\n",
    "\n",
    "  * **`.dt` Accessor:**\n",
    "      * **Time Complexity:** All `.dt` property access (like `.dt.year`) is **O(n)**. The calculation is vectorized and very fast.\n",
    "      * **Memory Usage:** Accessing a `.dt` property creates a *new Series* (a copy) containing the extracted data (e.g., a Series of `int`s for the year). This is generally small.\n",
    "  * **`category` Type:**\n",
    "      * **Time Complexity (Creation):** `.astype('category')` is **O(n log k)** or `O(n + k)`, where 'n' is rows and 'k' is unique categories. It has to find all unique values and create the codes. This is a one-time cost.\n",
    "      * **Time Complexity (Operations):** Operations like `groupby('my_cat_col')` are *significantly faster* on a `category` column than an `object` column, because Pandas can group on the underlying integers.\n",
    "      * **Memory Usage:** This is the main point. `category` can be **10-100x more memory-efficient** than `object` for low-cardinality columns.\n",
    "\n",
    "-----\n",
    "\n",
    "### 15\\. When NOT to Use This\n",
    "\n",
    "  * **When NOT to use `.dt`:**\n",
    "      * You can't. If you have a `datetime64[ns]` column, `.dt` is the *only* correct way to access its components.\n",
    "  * **When NOT to use `category`:**\n",
    "      * **High-Cardinality Columns:** Do **NOT** use `.astype('category')` on a column where most values are unique (like 'Email', 'User\\_ID', 'Comment\\_Text'). It will use *more* memory and be *slower* because the `categories` list will be huge.\n",
    "      * **If you need to do string operations:** Once you convert to `category`, you lose the `.str` accessor. You can't do `s.cat.contains('A')`. You must use the `categories` themselves. (e.g., `s.cat.categories.str.contains('A')`). It's more complex.\n",
    "      * **If you are constantly adding new \"types\":** If your column is a \"tag\" field where new tags appear *constantly*, it's a bad fit. You would have to call `.cat.add_categories()` every time, which is inefficient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
