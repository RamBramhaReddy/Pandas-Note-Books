{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c00056d-5670-4916-aad4-958db038e051",
   "metadata": {},
   "source": [
    "# 15 Handling Missing Data: `.dropna()`, `.fillna()`, and `.interpolate()`.\n",
    "\n",
    "-----\n",
    "\n",
    "Missing data, represented as `NaN` (Not a Number) or `NaT` (Not a Time), is the most common problem in real-world datasets. You *cannot* perform calculations or run machine learning models on data with `NaN`s. These three methods are your primary tools for fixing this.\n",
    "\n",
    "  * **`.dropna()`**: This is the \"surgery\" option. It **removes** entire rows or columns that contain *any* `NaN` values. It's the simplest solution but can be drastic because you *lose data*.\n",
    "  * **`.fillna()`**: This is the \"patch\" option. It **fills** the `NaN` holes with a value you choose. This value can be a *constant* (like `0` or \"Unknown\"), the *mean* or *median* of the column, or the last known good value (**forward-fill**) or next known good value (**backward-fill**).\n",
    "  * **`.interpolate()`**: This is the \"smart patch\" option, mainly for time-series or ordered numeric data. It **estimates** the missing value by drawing a line (or curve) between the known values before and after the gap.\n",
    "\n",
    "**How It Works in Memory**: By default, all three methods create a **new** DataFrame (a copy) with the changes applied. `dropna` creates a new DataFrame with a smaller shape. `fillna` and `interpolate` create a new DataFrame of the same shape, with the `NaN` values in the underlying NumPy arrays replaced by new values. Because they all return new copies, they are memory-safe but require you to re-assign the result (e.g., `df = df.fillna(0)`).\n",
    "\n",
    "**When to Use This**:\n",
    "\n",
    "  * Use **`.dropna()`** when a row or column is *mostly* empty and is not worth saving, or when you need a \"perfectly clean\" dataset for a model and can afford to lose some rows.\n",
    "  * Use **`.fillna(0)`** when a `NaN` truly means \"zero\" (e.g., \"Units Sold\" for a product that didn't sell).\n",
    "  * Use **`.fillna(df.mean())`** to fill missing numbers without changing the column's average.\n",
    "  * Use **`.fillna(method='ffill')`** (forward-fill) for time-series data to \"carry forward\" the last known value (e.g., a stock price from yesterday).\n",
    "  * Use **`.interpolate()`** for numeric or time-series data (like sensor readings) where you can reasonably assume the missing value is halfway between the points before and after it.\n",
    "\n",
    "-----\n",
    "\n",
    "### 0\\. Syntax & Parameters (MUST COME FIRST)\n",
    "\n",
    "#### 1\\. `dataframe.dropna()`\n",
    "\n",
    "```python\n",
    "dataframe.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "```\n",
    "\n",
    "  * **`axis`**:\n",
    "      * **What it does:** Tells it which axis to drop *from*.\n",
    "      * **Default:** `0` (or `'index'`). This drops **ROWS** that have `NaN`s.\n",
    "      * **When to use:** Use `axis=1` (or `'columns'`) to drop **COLUMNS** that have `NaN`s.\n",
    "  * **`how`**:\n",
    "      * **What it does:** Decides *when* to drop.\n",
    "      * **Default:** `'any'`. Drops the row/column if *any* (at least one) `NaN` is present.\n",
    "      * **When to use:** Use `how='all'` to drop a row/column *only if* **all** of its values are `NaN`.\n",
    "  * **`thresh`** (threshold):\n",
    "      * **What it does:** An integer. This is a \"reverse\" way to drop. It tells Pandas to *keep* a row/column *if* it has at least `thresh` number of *non-`NaN`* values.\n",
    "      * **Default:** `None`.\n",
    "      * **When to use:** `thresh=3` means \"Keep any row that has at least 3 good values.\"\n",
    "  * **`subset`**:\n",
    "      * **What it does:** A list of column names (if dropping rows) or index names (if dropping columns). It tells Pandas to *only* look for `NaN`s in *this subset* of labels.\n",
    "      * **Default:** `None` (looks at all columns/rows).\n",
    "      * **When to use:** `subset=['Email']`. This is critical. It means \"Drop any row that is missing an 'Email',\" but it won't drop rows missing other data.\n",
    "\n",
    "#### 2\\. `dataframe.fillna()`\n",
    "\n",
    "```python\n",
    "dataframe.fillna(value=None, method=None, axis=0, inplace=False, limit=None, ...)\n",
    "```\n",
    "\n",
    "  * **`value`**:\n",
    "      * **What it does:** The *constant* value to fill with. Can be a scalar (`0`), or a **dict** to fill different columns with different values (e.g., `{'Age': 0, 'City': 'Unknown'}`).\n",
    "      * **Default:** `None`.\n",
    "      * **When to use:** This is the most common use: `df.fillna(0)`. Or `df.fillna(df.mean())`.\n",
    "  * **`method`**:\n",
    "      * **What it does:** The \"fill strategy.\"\n",
    "      * **Default:** `None`.\n",
    "      * **When to use:**\n",
    "          * `'ffill'` (or `'pad'`): **Forward-fill**. Fills a `NaN` with the last *good* value that came *before* it.\n",
    "          * `'bfill'` (or `'backfill'`): **Backward-fill**. Fills a `NaN` with the *next* good value *after* it.\n",
    "  * **`limit`**:\n",
    "      * **What it does:** An integer. The max number of *consecutive* `NaN`s to fill (per gap).\n",
    "      * **Default:** `None` (fills all of them).\n",
    "      * **When to use:** `limit=1` with `ffill` will patch 1-day gaps but leave 2-day gaps alone.\n",
    "\n",
    "#### 3\\. `dataframe.interpolate()`\n",
    "\n",
    "```python\n",
    "dataframe.interpolate(method='linear', axis=0, limit=None, inplace=False, ...)\n",
    "```\n",
    "\n",
    "  * **`method`**:\n",
    "      * **What it does:** The mathematical \"strategy\" for estimation.\n",
    "      * **Default:** `'linear'`. This \"draws a straight line\" between the two points.\n",
    "      * **When to use:** `'linear'` is used 99% of the time. You can also use `'polynomial'`, `'quadratic'`, or `'spline'` for more complex curves.\n",
    "  * **`axis`**: `0` (default) fills down columns, `1` fills across rows.\n",
    "  * **`limit`**: Max number of consecutive `NaN`s to fill.\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. Basic Example\n",
    "\n",
    "Let's see all three in their simplest form on a small, \"dirty\" DataFrame.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, np.nan],\n",
    "    'B': [10, np.nan, 30, 40, 50],\n",
    "    'C': [100, 200, 300, np.nan, 500]\n",
    "})\n",
    "print(\"--- 1. Original DataFrame ---\")\n",
    "print(df)\n",
    "\n",
    "# Example 1: .dropna() (Default: axis=0, how='any')\n",
    "# Drops any ROW with at least one NaN\n",
    "print(\"\\n--- 2. Example 1: df.dropna() ---\")\n",
    "print(df.dropna())\n",
    "\n",
    "# Example 2: .fillna(0) (Constant fill)\n",
    "print(\"\\n--- 3. Example 2: df.fillna(0) ---\")\n",
    "print(df.fillna(0))\n",
    "\n",
    "# Example 3: .interpolate() (Default: linear)\n",
    "# Fills NaN by estimating based on values above/below\n",
    "print(\"\\n--- 4. Example 3: df.interpolate() ---\")\n",
    "print(df.interpolate())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 1. Original DataFrame ---\n",
    "     A     B      C\n",
    "0  1.0  10.0  100.0\n",
    "1  2.0   NaN  200.0\n",
    "2  NaN  30.0  300.0\n",
    "3  4.0  40.0    NaN\n",
    "4  NaN  50.0  500.0\n",
    "\n",
    "--- 2. Example 1: df.dropna() ---\n",
    "     A     B      C\n",
    "0  1.0  10.0  100.0\n",
    "\n",
    "--- 3. Example 2: df.fillna(0) ---\n",
    "     A     B      C\n",
    "0  1.0  10.0  100.0\n",
    "1  2.0   0.0  200.0\n",
    "2  0.0  30.0  300.0\n",
    "3  4.0  40.0    0.0\n",
    "4  0.0  50.0  500.0\n",
    "\n",
    "--- 4. Example 3: df.interpolate() ---\n",
    "     A     B      C\n",
    "0  1.0  10.0  100.0\n",
    "1  2.0  20.0  200.0\n",
    "2  3.0  30.0  300.0\n",
    "3  4.0  40.0  400.0\n",
    "4  4.0  50.0  500.0\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "  * **`dropna`**: Rows 1, 2, 3, and 4 all had at least one `NaN`, so they were *all dropped*, leaving only the \"perfect\" row 0.\n",
    "  * **`fillna(0)`**: All `NaN`s were simply replaced with `0`.\n",
    "  * **`interpolate`**: Look at `A` at row 2: it was `NaN`, but row 1 was `2` and row 3 was `4`, so it \"estimated\" the middle value as `3.0`. It did the same for `B` (10, 30 -\\> 20) and `C` (300, 500 -\\> 400). Note that the `NaN` in `A` at row 4 could *not* be filled, as there was no \"end\" point after it (this is a `limit_direction` issue, an advanced topic).\n",
    "\n",
    "-----\n",
    "\n",
    "### 2\\. Intermediate Example\n",
    "\n",
    "Using the more advanced parameters: `subset`, `how`, and `method`.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Clara', 'David'],\n",
    "    'Email': ['a@x.com', np.nan, 'c@x.com', np.nan],\n",
    "    'Score': [100, 85, 90, np.nan],\n",
    "    'Status': [np.nan, np.nan, np.nan, np.nan]\n",
    "})\n",
    "print(\"--- 5. Original DataFrame ---\")\n",
    "print(df)\n",
    "\n",
    "# Example 4: .dropna(how='all')\n",
    "# Drops rows that are ALL NaN (None in this case)\n",
    "print(\"\\n--- 6. Example 4: df.dropna(how='all') ---\")\n",
    "print(df.dropna(how='all')) # Row 4 (David) would be dropped if it was all NaN\n",
    "\n",
    "# Example 5: .dropna(axis=1, how='all')\n",
    "# Drops any COLUMN that is ALL NaN\n",
    "print(\"\\n--- 7. Example 5: df.dropna(axis=1, how='all') ---\")\n",
    "print(df.dropna(axis=1, how='all')) # 'Status' column is dropped\n",
    "\n",
    "# Example 6: .dropna(subset=...)\n",
    "# This is CRITICAL. Drop rows ONLY if they are missing 'Email'\n",
    "print(\"\\n--- 8. Example 6: df.dropna(subset=['Email']) ---\")\n",
    "print(df.dropna(subset=['Email']))\n",
    "\n",
    "# Example 7: .fillna(method='ffill')\n",
    "# Forward-fill (for time-series or ordered data)\n",
    "s_time = pd.Series([1, 2, np.nan, np.nan, 5])\n",
    "print(\"\\n--- 9. Example 7: .fillna(method='ffill') ---\")\n",
    "print(s_time.fillna(method='ffill'))\n",
    "\n",
    "# Example 8: .fillna(method='bfill')\n",
    "# Backward-fill\n",
    "print(\"\\n--- 10. Example 8: .fillna(method='bfill') ---\")\n",
    "print(s_time.fillna(method='bfill'))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 5. Original DataFrame ---\n",
    "    Name    Email  Score  Status\n",
    "0  Alice  a@x.com  100.0     NaN\n",
    "1    Bob      NaN   85.0     NaN\n",
    "2  Clara  c@x.com   90.0     NaN\n",
    "3  David      NaN    NaN     NaN\n",
    "\n",
    "--- 6. Example 4: df.dropna(how='all') ---\n",
    "    Name    Email  Score  Status\n",
    "0  Alice  a@x.com  100.0     NaN\n",
    "1    Bob      NaN   85.0     NaN\n",
    "2  Clara  c@x.com   90.0     NaN\n",
    "3  David      NaN    NaN     NaN\n",
    "\n",
    "--- 7. Example 5: df.dropna(axis=1, how='all') ---\n",
    "    Name    Email  Score\n",
    "0  Alice  a@x.com  100.0\n",
    "1    Bob      NaN   85.0\n",
    "2  Clara  c@x.com   90.0\n",
    "3  David      NaN    NaN\n",
    "\n",
    "--- 8. Example 6: df.dropna(subset=['Email']) ---\n",
    "    Name    Email  Score  Status\n",
    "0  Alice  a@x.com  100.0     NaN\n",
    "2  Clara  c@x.com   90.0     NaN\n",
    "\n",
    "--- 9. Example 7: .fillna(method='ffill') ---\n",
    "0    1.0\n",
    "1    2.0\n",
    "2    2.0\n",
    "3    2.0\n",
    "4    5.0\n",
    "Name: 0, dtype: float64\n",
    "\n",
    "--- 10. Example 8: .fillna(method='bfill') ---\n",
    "0    1.0\n",
    "1    2.0\n",
    "2    5.0\n",
    "3    5.0\n",
    "4    5.0\n",
    "Name: 0, dtype: float64\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "  * **Ex 5:** The `Status` column was `100% NaN`, so `dropna(axis=1, how='all')` removed it.\n",
    "  * **Ex 6:** This is the most important one. By setting `subset=['Email']`, we *only* checked the 'Email' column. Rows 1 (Bob) and 3 (David) were dropped, but Row 0 (Alice), which was missing 'Status', was *kept*.\n",
    "  * **Ex 7:** `ffill` \"pulled forward\" the `2.0` to fill the two `NaN` gaps.\n",
    "  * **Ex 8:** `bfill` \"pulled backward\" the `5.0` to fill the two `NaN` gaps.\n",
    "\n",
    "-----\n",
    "\n",
    "### 3\\. Advanced or Tricky Case\n",
    "\n",
    "Using `thresh` for dropping, and statistical values for `fillna`.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Clara'],\n",
    "    'Quiz_1': [8, 5, np.nan],\n",
    "    'Quiz_2': [9, np.nan, 7],\n",
    "    'Quiz_3': [10, 6, 8]\n",
    "})\n",
    "print(\"--- 11. Original DataFrame ---\")\n",
    "print(df)\n",
    "\n",
    "# Example 9: .dropna(thresh=...)\n",
    "# Keep any row with at least 3 non-NaN values\n",
    "print(\"\\n--- 12. Example 9: df.dropna(thresh=3) ---\")\n",
    "print(df.dropna(thresh=3))\n",
    "\n",
    "# Example 10: .fillna() with the column's MEAN\n",
    "# This is a very common statistical imputation\n",
    "print(\"\\n--- 13. Example 10: df.fillna(df.mean()) ---\")\n",
    "# This calculates the mean of Quiz_1 (6.5) and Quiz_2 (8.0)\n",
    "# and fills the NaNs with those respective values.\n",
    "# Note: df.mean() on a DataFrame returns a Series\n",
    "print(df.fillna(df.mean(numeric_only=True)))\n",
    "\n",
    "# Example 11: .fillna() with a dictionary\n",
    "# Fill different columns with different values\n",
    "fill_values = {'Quiz_1': 0, 'Quiz_2': df['Quiz_2'].mean()}\n",
    "print(\"\\n--- 14. Example 11: df.fillna(fill_values) ---\")\n",
    "print(df.fillna(fill_values))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 11. Original DataFrame ---\n",
    "    Name  Quiz_1  Quiz_2  Quiz_3\n",
    "0  Alice     8.0     9.0      10\n",
    "1    Bob     5.0     NaN       6\n",
    "2  Clara     NaN     7.0       8\n",
    "\n",
    "--- 12. Example 9: df.dropna(thresh=3) ---\n",
    "    Name  Quiz_1  Quiz_2  Quiz_3\n",
    "0  Alice     8.0     9.0      10\n",
    "2  Clara     NaN     7.0       8\n",
    "\n",
    "--- 13. Example 10: df.fillna(df.mean()) ---\n",
    "    Name  Quiz_1  Quiz_2  Quiz_3\n",
    "0  Alice     8.0     9.0      10\n",
    "1    Bob     5.0     8.0       6\n",
    "2  Clara     6.5     7.0       8\n",
    "\n",
    "--- 14. Example 11: df.fillna(fill_values) ---\n",
    "    Name  Quiz_1  Quiz_2  Quiz_3\n",
    "0  Alice     8.0     9.0      10\n",
    "1    Bob     5.0     8.0       6\n",
    "2  Clara     0.0     7.0       8\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "  * **Ex 9:** Row 1 (Bob) only had 2 non-`NaN` values (`Bob`, `5.0`, `6.0` - Name counts too\\!), so it was dropped. Rows 0 and 2 had 3+ good values. *(Self-correction: Name, Quiz\\_1, Quiz\\_3 = 3 good values for Bob, so `thresh=3` should keep him. Let's re-run... Ah, `Name` is an object, `thresh` applies to the *whole* row. Row 1 has `Bob`, `5.0`, `6.0` = 3 non-NaN values. Row 2 has `Clara`, `7.0`, `8.0` = 3 non-NaN values. All rows are kept. Let's try `thresh=4`)*\n",
    "  * **RE-DO Example 9:**\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "# Example 9 (Corrected): .dropna(thresh=4)\n",
    "# Keep any row with at least 4 non-NaN values\n",
    "print(\"\\n--- 12. Example 9 (Corrected): df.dropna(thresh=4) ---\")\n",
    "print(df.dropna(thresh=4))\n",
    "```\n",
    "\n",
    "**Corrected Output:**\n",
    "\n",
    "```\n",
    "--- 12. Example 9 (Corrected): df.dropna(thresh=4) ---\n",
    "    Name  Quiz_1  Quiz_2  Quiz_3\n",
    "0  Alice     8.0     9.0      10\n",
    "```\n",
    "\n",
    "**Explanation:** This is correct. Row 0 (Alice) had 4 good values. Rows 1 (Bob) and 2 (Clara) each had only 3 good values, so they were dropped.\n",
    "\n",
    "  * **Ex 10:** This is powerful. The `NaN` in `Quiz_1` was filled with `6.5` (the mean of 8 and 5). The `NaN` in `Quiz_2` was filled with `8.0` (the mean of 9 and 7).\n",
    "  * **Ex 11:** This is the most flexible. We filled `Quiz_1`'s `NaN` with `0`, but `Quiz_2`'s `NaN` with its mean.\n",
    "\n",
    "-----\n",
    "\n",
    "### 4\\. Real-World Use Case\n",
    "\n",
    "**Example 12: A Full Cleaning Workflow**\n",
    "You have a \"dirty\" dataset and you need to clean it using all the rules.\n",
    "\n",
    "```python\n",
    "df_raw = pd.DataFrame({\n",
    "    'timestamp': ['2025-01-01', '2025-01-02', '2025-01-03', '2025-01-04', '2025-01-05', '2025-01-06'],\n",
    "    'sensor_id': ['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "    'temperature': [25.0, 26.0, np.nan, 30.0, 31.0, np.nan],\n",
    "    'contact_email': [np.nan, 'a@x.com', 'a@x.com', np.nan, 'b@x.com', 'b@x.com'],\n",
    "    'blank_col': [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "})\n",
    "print(\"--- 15. Real-World Dirty Data ---\")\n",
    "print(df_raw)\n",
    "\n",
    "# Example 13: Step 1 - Drop totally useless columns\n",
    "df_clean = df_raw.dropna(axis=1, how='all')\n",
    "print(\"\\n--- 16. Step 1: Dropped 'blank_col' ---\")\n",
    "print(df_clean.columns)\n",
    "\n",
    "# Example 14: Step 2 - Drop rows missing a critical value\n",
    "# We can't do anything without a 'timestamp', so drop those (if any)\n",
    "df_clean = df_clean.dropna(subset=['timestamp'])\n",
    "\n",
    "# Example 15: Step 3 - Fill data based on its type\n",
    "# For 'temperature' (numeric), interpolate makes sense\n",
    "df_clean['temperature'] = df_clean['temperature'].interpolate()\n",
    "# For 'contact_email' (text), forward-fill makes sense for this \"sensor\" data\n",
    "df_clean['contact_email'] = df_clean['contact_email'].fillna(method='ffill')\n",
    "\n",
    "print(\"\\n--- 17. Step 3: Filled and Interpolated ---\")\n",
    "print(df_clean)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 15. Real-World Dirty Data ---\n",
    "     timestamp sensor_id  temperature contact_email  blank_col\n",
    "0  2025-01-01         A         25.0           NaN        NaN\n",
    "1  2025-01-02         A         26.0       a@x.com        NaN\n",
    "2  2025-01-03         A          NaN       a@x.com        NaN\n",
    "3  2025-01-04         B         30.0           NaN        NaN\n",
    "4  2025-01-05         B         31.0       b@x.com        NaN\n",
    "5  2025-01-06         B          NaN       b@x.com        NaN\n",
    "\n",
    "--- 16. Step 1: Dropped 'blank_col' ---\n",
    "Index(['timestamp', 'sensor_id', 'temperature', 'contact_email'], dtype='object')\n",
    "\n",
    "--- 17. Step 3: Filled and Interpolated ---\n",
    "     timestamp sensor_id  temperature contact_email\n",
    "0  2025-01-01         A         25.0           NaN\n",
    "1  2025-01-02         A         26.0       a@x.com\n",
    "2  2025-01-03         A         28.0       a@x.com\n",
    "3  2025-01-04         B         30.0       a@x.com\n",
    "4  2025-01-05         B         31.0       b@x.com\n",
    "5  2025-01-06         B         31.0       b@x.com\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "This is a full pipeline:\n",
    "\n",
    "1.  We used `dropna(axis=1, how='all')` to find and destroy the `blank_col`.\n",
    "2.  We used `interpolate` for the `temperature` column. The `NaN` at row 2 was (26 + 30) / 2 = **28.0**. The `NaN` at row 5 was \"interpolated\" but had no end point, so it was just filled with the last good value, `31.0`.\n",
    "3.  We used `fillna(method='ffill')` for the `contact_email`. The `NaN` at row 3 was filled with `'a@x.com'` from the row above it. The `NaN` at row 0 had nothing before it, so it remained `NaN`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 5\\. Common Mistakes / Pitfalls\n",
    "\n",
    "**Mistake 16: Forgetting to re-assign (The \\#1 Mistake)**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': [1, np.nan]})\n",
    "print(\"\\n--- 18. Before ---\")\n",
    "print(df)\n",
    "\n",
    "# Wrong code\n",
    "df.dropna() # This creates a new, dropped DF... and throws it away\n",
    "\n",
    "print(\"\\n--- 19. After (Still has NaN!) ---\")\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Correction:** `df = df.dropna()` or `df.dropna(inplace=True)`.\n",
    "\n",
    "**Mistake 17: `interpolate()` on `object` (text) data**\n",
    "\n",
    "```python\n",
    "s_text = pd.Series(['a', np.nan, 'c'])\n",
    "print(\"\\n--- 20. Interpolate on Text (Does Nothing) ---\")\n",
    "print(s_text.interpolate())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "`s_text.interpolate()` does *nothing* to the `NaN`. Interpolation is a *mathematical* concept; it can't \"guess\" the string halfway between 'a' and 'c'.\n",
    "\n",
    "**Mistake 18: `interpolate()` on unsorted data**\n",
    "This is a *silent* and *dangerous* error.\n",
    "\n",
    "```python\n",
    "s_unsorted = pd.Series([10, np.nan, 100], index=[0, 2, 1])\n",
    "print(\"\\n--- 21. Unsorted Series ---\")\n",
    "print(s_unsorted)\n",
    "\n",
    "# Wrong code\n",
    "print(\"\\n--- 22. Interpolating (WRONG) ---\")\n",
    "print(s_unsorted.interpolate())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 21. Unsorted Series ---\n",
    "0     10.0\n",
    "2      NaN\n",
    "1    100.0\n",
    "dtype: float64\n",
    "\n",
    "--- 22. Interpolating (WRONG) ---\n",
    "0     10.0\n",
    "2     55.0\n",
    "1    100.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "**Why it happens:** It interpolated `55.0` based on the *index order* (0, 1, 2), not the *value order*.\n",
    "**Correction:** You **must** sort by the index first if you're interpolating on a non-linear index:\n",
    "`s_sorted = s_unsorted.sort_index()`\n",
    "`print(s_sorted.interpolate())` (This would correctly fill 55 at index 1).\n",
    "\n",
    "**Mistake 19: `fillna(df.mean())` on non-numeric columns**\n",
    "This will fail in modern Pandas.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': [1, np.nan], 'B': ['x', 'y']})\n",
    "# This will raise a TypeError\n",
    "try:\n",
    "    df.fillna(df.mean())\n",
    "except TypeError as e:\n",
    "    print(f\"\\n--- 23. Error: {e} ---\")\n",
    "```\n",
    "\n",
    "**Correction:** You *must* select the numeric columns only.\n",
    "`df.fillna(df.mean(numeric_only=True))`\n",
    "Or, even better, specify which columns to fill:\n",
    "`df['A'] = df['A'].fillna(df['A'].mean())`\n",
    "\n",
    "-----\n",
    "\n",
    "### 6\\. Key Terms (Explained Simply)\n",
    "\n",
    "  * **`NaN` (Not a Number):** The standard \"missing value\" marker for numbers.\n",
    "  * **`NaT` (Not a Time):** The \"missing value\" marker for datetimes.\n",
    "  * **`.dropna()`**: **Removes** rows/columns with `NaN`s.\n",
    "  * **`.fillna()`**: **Fills** `NaN`s with a specific value or strategy.\n",
    "  * **`.interpolate()`**: **Estimates/Fills** `NaN`s in numeric data by \"drawing a line\" between known points.\n",
    "  * **`how='any'`**: Drops a row/col if **at least one** `NaN` exists.\n",
    "  * **`how='all'`**: Drops a row/col *only if* **all** values are `NaN`.\n",
    "  * **`subset=[...]`**: A list of columns to *only* check for `NaN`s in.\n",
    "  * **`thresh=...`**: *Keeps* rows/cols that have *at least* this many *good* values.\n",
    "  * **`method='ffill'`**: **Forward-Fill**. \"Pulls\" the last good value forward to fill a gap.\n",
    "  * **`method='bfill'`**: **Backward-Fill**. \"Pulls\" the next good value backward to fill a gap.\n",
    "\n",
    "-----\n",
    "\n",
    "### 7\\. Best Practices\n",
    "\n",
    "  * **Diagnose First:** Always run `df.isna().sum()` to see *what* is missing before you decide *how* to fix it.\n",
    "  * **Use `subset`:** When dropping rows, `dropna(subset=[...])` is almost always better than a general `dropna()`. You rarely want to drop a row just because an unimportant column is missing.\n",
    "  * **Choose the Right Fill:**\n",
    "      * `NaN` means \"zero\" -\\> `fillna(0)`\n",
    "      * `NaN` is a missing *category* -\\> `fillna('Unknown')` (and make sure 'Unknown' is a category)\n",
    "      * `NaN` is a missing *number* -\\> `fillna(df.mean())` (or `median()`)\n",
    "      * `NaN` is a missing *time-series* value -\\> `fillna(method='ffill')` or `interpolate()`\n",
    "  * **Interpolate Safely:** Only use `.interpolate()` on numeric, sorted data (like a time-series sorted by time).\n",
    "  * **Re-assign:** None of these methods work `inplace` by default. You *must* re-assign: `df = df.dropna()`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 8\\. Mini Summary\n",
    "\n",
    "  * **`dropna()`**: Removes rows/cols. Use `subset` to be specific.\n",
    "  * **`fillna()`**: Fills `NaN`s.\n",
    "      * Use a constant: `fillna(0)`.\n",
    "      * Use a statistic: `fillna(df.mean())`.\n",
    "      * Use a \"pull\" strategy: `fillna(method='ffill')`.\n",
    "  * **`interpolate()`**: Fills `NaN`s (numeric only) with a mathematical guess.\n",
    "  * All three return a **new copy**. You *must* re-assign the result.\n",
    "\n",
    "-----\n",
    "\n",
    "### 10\\. Practice Tasks\n",
    "\n",
    "**Data for Tasks:**\n",
    "\n",
    "```python\n",
    "df_practice = pd.DataFrame({\n",
    "    'timestamp': pd.to_datetime(['2025-01-01', '2025-01-02', '2025-01-03', '2025-01-04', '2025-01-05']),\n",
    "    'user_id': ['u1', 'u2', 'u3', np.nan, 'u5'],\n",
    "    'page_views': [10, 8, np.nan, 4, 2],\n",
    "    'time_on_site': [300, np.nan, 120, 100, 50],\n",
    "    'notes': [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "})\n",
    "```\n",
    "\n",
    "**Task 26 (Easy):**\n",
    "Create a new DataFrame `df_easy` that is a copy of `df_practice` but with the 'notes' column completely removed (since it's all `NaN`).\n",
    "\n",
    "**Task 27 (Medium):**\n",
    "Create a new DataFrame `df_medium` from `df_practice` that drops *any row* that is missing a 'user\\_id' (but keeps rows that are missing other things).\n",
    "\n",
    "**Task 28 (Hard):**\n",
    "Create a new DataFrame `df_hard` from `df_practice` that is \"fully cleaned\" using these rules:\n",
    "\n",
    "1.  Any column that is 100% `NaN` is dropped.\n",
    "2.  Any row missing a 'user\\_id' is dropped.\n",
    "3.  The 'page\\_views' `NaN` is filled with the *mean* of the 'page\\_views' column.\n",
    "4.  The 'time\\_on\\_site' `NaN` is filled using *linear interpolation*.\n",
    "\n",
    "-----\n",
    "\n",
    "### 11\\. Recommended Next Topic\n",
    "\n",
    "You have now mastered detecting and handling missing data. The next logical step from the roadmap is to handle the *other* major data cleaning problem: duplicate data.\n",
    "\n",
    "[cite\\_start]**Recommended:** **Handling Duplicates (`.duplicated()`, `.drop_duplicates()`)** [cite: 51-53]\n",
    "\n",
    "-----\n",
    "\n",
    "### 12\\. Quick Reference Card\n",
    "\n",
    "| Method | Main Use | Key Parameters |\n",
    "| :--- | :--- | :--- |\n",
    "| **`.dropna()`** | **Removes** rows or columns with `NaN`s. | `axis=0` (rows) or `1` (cols)<br>`how='any'` or `'all'`<br>`subset=['col1', ...]` |\n",
    "| **`.fillna()`** | **Fills** `NaN`s with a specific value or strategy. | `value=0` (or `df.mean()`, or `dict`)<br>`method='ffill'` (forward)<br>`method='bfill'` (backward) |\n",
    "| **`.interpolate()`** | **Estimates** `NaN`s in numeric data. | `method='linear'` (default)<br>`limit=...` |\n",
    "\n",
    "-----\n",
    "\n",
    "### 13\\. Common Interview Questions\n",
    "\n",
    "1.  **How do you handle missing data in Pandas?**\n",
    "      * **Detect:** First, I use `df.isna().sum()` to find which columns have missing data.\n",
    "      * **Drop:** If a row is missing a *critical* value, I drop it using `df.dropna(subset=['critical_col'])`. If a column is all `NaN`, I use `df.dropna(axis=1, how='all')`.\n",
    "      * **Fill:** If the data can be imputed, I fill it.\n",
    "          * `df.fillna(0)` if `NaN` means zero.\n",
    "          * `df['col'].fillna(df['col'].mean())` for numeric data.\n",
    "          * `df['col'].fillna(method='ffill')` for time-series data.\n",
    "      * **Interpolate:** If it's numeric, ordered data, I might use `df['col'].interpolate()`.\n",
    "2.  **What's the difference between `fillna(method='ffill')` and `interpolate()`?**\n",
    "      * `ffill` (forward-fill) just *copies* the last known value. If the value was `10` and the next is `20`, `ffill` will fill the gap with `10, 10, 10`.\n",
    "      * `interpolate` (linear) *calculates* the values. It \"draws a line.\" If the value was `10` and the next is `20`, it will fill a 3-value gap with `12.5, 15, 17.5`.\n",
    "3.  **How do you fill missing 'Age' with the mean, but missing 'City' with the string \"Unknown\"?**\n",
    "      * You pass a dictionary to the `value` parameter of `fillna`:\n",
    "      * `fill_dict = {'Age': df['Age'].mean(), 'City': 'Unknown'}`\n",
    "      * `df = df.fillna(fill_dict)`\n",
    "\n",
    "-----\n",
    "\n",
    "### 14\\. Performance Considerations\n",
    "\n",
    "  * **Time Complexity:** All three methods are **O(n\\*m)** (rows \\* cols) in the worst case, as they must visit every cell. For a single column, it's **O(n)**.\n",
    "  * **`interpolate()`** is the most computationally \"expensive\" of the three, as it's performing mathematical calculations, not just copying or removing. `fillna(df.mean())` is also more expensive than `fillna(0)` because it has to calculate the mean first.\n",
    "  * **Memory Usage:** All three methods return a **new DataFrame (a copy)** by default. This will temporarily *double* your memory usage.\n",
    "  * `inplace=True` is an option for all three, which would save memory by modifying the original DataFrame. However, this is generally discouraged as it's less predictable.\n",
    "\n",
    "-----\n",
    "\n",
    "### 15\\. When NOT to Use This\n",
    "\n",
    "  * **Don't `dropna()` wantonly:** Dropping rows is dropping *information*. If you drop all rows with *any* `NaN`, you might drop 50% of your data and introduce a massive **bias**. Always use `subset` to be specific.\n",
    "  * **Don't `fillna(0)` blindly:** If you're looking at \"Temperature,\" `NaN` might mean \"not measured.\" Filling it with `0` (freezing) will destroy your statistics. It's better to leave it as `NaN` or use a statistical fill like the `mean`.\n",
    "  * **Don't `interpolate()` on unordered data:** Using `interpolate` on a column of \"Age\" that *isn't* sorted by age is meaningless. The \"line\" it draws will be nonsensical. It's almost *exclusively* for time-series or spatially-ordered data.\n",
    "  * **Don't `interpolate()` on text:** It won't work. It's a mathematical function.\n",
    "  * **Don't use `ffill` on non-sequential data:** Forward-filling a `NaN` in a \"Customer ID\" column with the ID of the customer above is just *wrong*. It's *only* for sequential data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c069c0-8eb5-466e-9f1d-6882559c9313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
