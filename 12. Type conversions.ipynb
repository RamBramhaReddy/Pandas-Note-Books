{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5259d157-9eec-43d4-9c53-3e4045994a37",
   "metadata": {},
   "source": [
    "# 12. Type conversions first subtopic: `.astype()`.\n",
    "\n",
    "-----\n",
    "\n",
    "The `.astype()` method is your primary, all-purpose tool for changing the data type of a Series or an entire DataFrame. Think of it as a \"type-casting\" command. You use it when you *know* the data is in the wrong format and you want to *force* Pandas to change it.\n",
    "\n",
    "For example, a column of numbers (`1`, `2`, `3`) might be loaded as text (`'1'`, `'2'`, `'3'`), which Pandas calls an `object` type. You can't do math on text. `.astype(int)` is the command you use to \"re-cast\" that text into actual numbers.\n",
    "\n",
    "**How It Works in Memory**: `.astype()` *always* returns a **new** Series or DataFrame (a copy) with the new data type. It does this by creating a new NumPy array in memory for each column being converted and then copying the data over, changing its type in the process. Because it's a copy, it's a memory-intensive operation—your DataFrame will temporarily take up twice the memory.\n",
    "\n",
    "**When to Use This**:\n",
    "\n",
    "  * **Always use this** when you need to change from one valid type to another (e.g., `int` to `float`, `float` to `int`, `object` to `int`, `object` to `category`).\n",
    "  * Use it to convert text (`object`) to numbers (`int` or `float`) when you are **100% sure** the column contains *only* numbers (or text that looks like numbers).\n",
    "  * Use it to convert text (`object`) to `category` to save memory.\n",
    "  * Use it to \"downcast\" types to save memory (e.g., from `int64` to `int32`).\n",
    "\n",
    "-----\n",
    "\n",
    "### 0\\. Syntax & Parameters (MUST COME FIRST)\n",
    "\n",
    "This method can be called on a Series or a DataFrame.\n",
    "\n",
    "#### `series.astype()`\n",
    "\n",
    "```python\n",
    "series.astype(dtype, copy=True, errors='raise')\n",
    "```\n",
    "\n",
    "#### `dataframe.astype()`\n",
    "\n",
    "```python\n",
    "dataframe.astype(dtype, copy=True, errors='raise')\n",
    "```\n",
    "\n",
    "  * **`dtype`**\n",
    "      * **What it does:** This is the most important parameter. It's the target data type you want to convert *to*.\n",
    "      * **Default value:** (Required)\n",
    "      * **When you would use it:** You *always* provide this.\n",
    "          * **For a Series:** `s.astype(int)` or `s.astype('int64')` or `s.astype(np.int64)`.\n",
    "          * **For a DataFrame:** You pass a **dictionary** mapping columns to types: `df.astype({'col_A': int, 'col_B': float})`.\n",
    "  * **`copy`**\n",
    "      * **What it does:** A boolean (True/False). By default, it *always* makes a copy. Setting `copy=False` tells Pandas to *try* not to make a copy *if* the data type is already correct.\n",
    "      * **Default value:** `True`\n",
    "      * **When you would use it:** You almost never change this. The default `True` is safer and more predictable.\n",
    "  * **`errors`**\n",
    "      * **What it does:** Tells Pandas what to do if it finds a value it *cannot* convert.\n",
    "      * **Default value:** `'raise'`\n",
    "      * **When you would use it:**\n",
    "          * `'raise'`: The default. It will stop your code and show a `ValueError` (e.g., if you try to `astype(int)` on the string `'hello'`).\n",
    "          * `'ignore'`: This is **dangerous**. It will silently fail, not perform the conversion, and return your *original* object. It's almost never what you want.\n",
    "      * **Note:** For handling bad data, `pd.to_numeric()` (our next topic) is *much* better because it has an `errors='coerce'` option.\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. Basic Example\n",
    "\n",
    "Let's do the most common conversions: from `object` (text) to `int` and `float` to `int`.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example 1: Basic conversion (float to int)\n",
    "s_float = pd.Series([1.0, 2.5, 3.9])\n",
    "print(\"--- 1. Original (float) ---\")\n",
    "print(s_float)\n",
    "print(f\"Dtype: {s_float.dtype}\")\n",
    "\n",
    "# This will TRUNCATE the decimals\n",
    "s_int = s_float.astype(int)\n",
    "print(\"\\n--- 2. After .astype(int) ---\")\n",
    "print(s_int)\n",
    "print(f\"Dtype: {s_int.dtype}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 1. Original (float) ---\n",
    "0    1.0\n",
    "1    2.5\n",
    "2    3.9\n",
    "dtype: float64\n",
    "Dtype: float64\n",
    "\n",
    "--- 2. After .astype(int) ---\n",
    "0    1\n",
    "1    2\n",
    "2    3\n",
    "dtype: int64\n",
    "Dtype: int64\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "`.astype(int)` successfully converted the Series. Note that it does *not* round—it **truncates** (cuts off) the decimal. `2.5` became `2`, and `3.9` became `3`.\n",
    "\n",
    "**Example 2: `object` (text) to `int`**\n",
    "This is the most common use case after loading a CSV.\n",
    "\n",
    "```python\n",
    "# 'Price' is loaded as text\n",
    "s_text = pd.Series(['100', '200', '300'])\n",
    "print(\"\\n--- 3. Original (text/object) ---\")\n",
    "print(s_text)\n",
    "print(f\"Dtype: {s_text.dtype}\")\n",
    "\n",
    "# Convert to numeric\n",
    "s_numeric = s_text.astype(int)\n",
    "print(\"\\n--- 4. After .astype(int) ---\")\n",
    "print(s_numeric)\n",
    "print(f\"Dtype: {s_numeric.dtype}\")\n",
    "\n",
    "# Now we can do math\n",
    "print(f\"\\nSum: {s_numeric.sum()}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 3. Original (text/object) ---\n",
    "0    100\n",
    "1    200\n",
    "2    300\n",
    "dtype: object\n",
    "Dtype: object\n",
    "\n",
    "--- 4. After .astype(int) ---\n",
    "0    100\n",
    "1    200\n",
    "2    300\n",
    "dtype: int64\n",
    "Dtype: int64\n",
    "\n",
    "Sum: 600\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "The original Series was `object` type (you can't do math on it). `s_text.sum()` would have just concatenated the strings. `s_numeric.sum()` works perfectly.\n",
    "\n",
    "-----\n",
    "\n",
    "### 2\\. Intermediate Example\n",
    "\n",
    "Using `.astype()` on a full DataFrame and converting to `category`.\n",
    "\n",
    "**Example 3: Using `astype` on a DataFrame with a `dict`**\n",
    "This is the standard way to clean multiple columns at once.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'A_str': ['1', '2', '3'],\n",
    "    'B_float': [10.5, 11.2, 12.9],\n",
    "    'C_keep': ['x', 'y', 'z']\n",
    "})\n",
    "print(\"--- 5. Original DataFrame ---\")\n",
    "df.info()\n",
    "\n",
    "# We want to change A to int and B to int\n",
    "df_clean = df.astype({'A_str': int, 'B_float': int})\n",
    "\n",
    "print(\"\\n--- 6. Cleaned DataFrame ---\")\n",
    "df_clean.info()\n",
    "\n",
    "print(\"\\n--- 7. Cleaned Data ---\")\n",
    "print(df_clean)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 5. Original DataFrame ---\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 3 entries, 0 to 2\n",
    "Data columns (total 3 columns):\n",
    " #   Column   Non-Null Count  Dtype  \n",
    "---  ------   --------------  -----  \n",
    " 0   A_str    3 non-null      object \n",
    " 1   B_float  3 non-null      float64\n",
    " 2   C_keep   3 non-null      object \n",
    "dtypes: float64(1), object(2)\n",
    "memory usage: 200.0+ bytes\n",
    "\n",
    "--- 6. Cleaned DataFrame ---\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 3 entries, 0 to 2\n",
    "Data columns (total 3 columns):\n",
    " #   Column   Non-Null Count  Dtype \n",
    "---  ------   --------------  ----- \n",
    " 0   A_str    3 non-null      int64 \n",
    " 1   B_float  3 non-null      int64 \n",
    " 2   C_keep   3 non-null      object\n",
    "dtypes: int64(2), object(1)\n",
    "memory usage: 200.0+ bytes\n",
    "\n",
    "--- 7. Cleaned Data ---\n",
    "   A_str  B_float C_keep\n",
    "0      1       10      x\n",
    "1      2       11      y\n",
    "2      3       12      z\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "By passing a dictionary `{'A_str': int, 'B_float': int}` to `df.astype()`, we changed *only* those two columns. `C_keep` was left alone, and `B_float` was truncated, just as in Example 1.\n",
    "\n",
    "**Example 4: Converting `object` to `category` (Memory Saver)**\n",
    "This is a *critical* optimization.\n",
    "\n",
    "```python\n",
    "# A Series with lots of repeated text\n",
    "s_gender = pd.Series(['Male', 'Female', 'Male', 'Male', 'Female'] * 1000)\n",
    "print(\"\\n--- 8. Original (object) ---\")\n",
    "print(s_gender.head())\n",
    "print(f\"Memory (object): {s_gender.memory_usage(deep=True)} bytes\")\n",
    "\n",
    "# Convert to category\n",
    "s_cat = s_gender.astype('category')\n",
    "print(\"\\n--- 9. Converted (category) ---\")\n",
    "print(s_cat.head())\n",
    "print(f\"Memory (category): {s_cat.memory_usage(deep=True)} bytes\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 8. Original (object) ---\n",
    "0      Male\n",
    "1    Female\n",
    "2      Male\n",
    "3      Male\n",
    "4    Female\n",
    "dtype: object\n",
    "Memory (object): 310040 bytes\n",
    "\n",
    "--- 9. Converted (category) ---\n",
    "0      Male\n",
    "1    Female\n",
    "2      Male\n",
    "3      Male\n",
    "4    Female\n",
    "dtype: category\n",
    "Categories (2, object): ['Female', 'Male']\n",
    "Memory (category): 7016 bytes\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "The `object` Series stores 5,000 full-text strings (\"Male\", \"Female\", ...). The `category` type is much smarter: it stores the unique values (`['Female', 'Male']`) *once* and then uses tiny integers (`0`, `1`) to point to them. The memory usage dropped from 310,000 bytes to 7,000 bytes. This is one of the most important uses of `.astype()`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 3\\. Advanced or Tricky Case\n",
    "\n",
    "Handling `NaN` (missing) values during conversion.\n",
    "\n",
    "**Example 5: `float` with `NaN` to `int` (The Old Way - Fails)**\n",
    "You cannot have `NaN` in a standard `int` column.\n",
    "\n",
    "```python\n",
    "s_nan = pd.Series([1.0, 2.0, np.nan])\n",
    "print(\"\\n--- 10. Original (float with NaN) ---\")\n",
    "print(s_nan)\n",
    "\n",
    "try:\n",
    "    s_nan.astype(int)\n",
    "except ValueError as e:\n",
    "    print(f\"\\n--- 11. Error ---\")\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 10. Original (float with NaN) ---\n",
    "0    1.0\n",
    "1    2.0\n",
    "2    NaN\n",
    "dtype: float64\n",
    "\n",
    "--- 11. Error ---\n",
    "Cannot convert non-finite values (NA or inf) to integer\n",
    "```\n",
    "\n",
    "**Example 6: The `Int64` (nullable integer) fix**\n",
    "Pandas created a special type `Int64` (capital \"I\") to fix this.\n",
    "\n",
    "```python\n",
    "# Use the string alias 'Int64' (capital I)\n",
    "s_nullable_int = s_nan.astype('Int64')\n",
    "print(\"\\n--- 12. Converted to 'Int64' (nullable) ---\")\n",
    "print(s_nullable_int)\n",
    "print(f\"Dtype: {s_nullable_int.dtype}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 12. Converted to 'Int64' (nullable) ---\n",
    "0       1\n",
    "1       2\n",
    "2    <NA>\n",
    "dtype: Int64\n",
    "Dtype: Int64\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "The `int64` (lowercase \"i\") type *cannot* hold `NaN`s. The special `Int64` (capital \"I\") type *can*. It stores the `NaN` as a special `<NA>` marker. This is extremely useful.\n",
    "\n",
    "**Example 7: Converting to `bool` (True/False)**\n",
    "`astype(bool)` has very specific rules.\n",
    "\n",
    "```python\n",
    "s_bool = pd.Series([0, 1, 10, -1, 0.0, 0.5])\n",
    "print(\"\\n--- 13. Numbers for bool conversion ---\")\n",
    "print(s_bool)\n",
    "\n",
    "print(\"\\n--- 14. After .astype(bool) ---\")\n",
    "print(s_bool.astype(bool))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 13. Numbers for bool conversion ---\n",
    "0     0.0\n",
    "1     1.0\n",
    "2    10.0\n",
    "3    -1.0\n",
    "4     0.0\n",
    "5     0.5\n",
    "dtype: float64\n",
    "\n",
    "--- 14. After .astype(bool) ---\n",
    "0    False\n",
    "1     True\n",
    "2     True\n",
    "3     True\n",
    "4    False\n",
    "5     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "When converting to `bool`, **only `0` and `0.0`** are `False`. *All* other numbers (positive, negative, or decimals like 0.5) are `True`.\n",
    "\n",
    "**Example 8: `object` to `bool`**\n",
    "This is even trickier and can be dangerous.\n",
    "\n",
    "```python\n",
    "s_text_bool = pd.Series(['True', 'False', 'TRUE', 'FALSE', 'true', 'false', 'T', 'F'])\n",
    "print(\"\\n--- 15. Text for bool conversion ---\")\n",
    "print(s_text_bool)\n",
    "\n",
    "print(\"\\n--- 16. After .astype(bool) ---\")\n",
    "print(s_text_bool.astype(bool))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 15. Text for bool conversion ---\n",
    "0     True\n",
    "1    False\n",
    "2     TRUE\n",
    "3    FALSE\n",
    "4     true\n",
    "5    false\n",
    "6        T\n",
    "7        F\n",
    "dtype: object\n",
    "\n",
    "--- 16. After .astype(bool) ---\n",
    "0    True\n",
    "1    True\n",
    "2    True\n",
    "3    True\n",
    "4    True\n",
    "5    True\n",
    "6    True\n",
    "7    True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "This is a **major pitfall**. When converting from `object` to `bool`, *any non-empty string* is `True`. Even the string `'False'` becomes `True`\\! To *properly* convert strings like 'True'/'False', you must use `.map({'True': True, 'False': False})`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 4\\. Real-World Use Case\n",
    "\n",
    "**Example 9: Cleaning a \"dirty\" DataFrame**\n",
    "You just loaded a file and `.info()` shows everything is an `object`.\n",
    "\n",
    "```python\n",
    "df_dirty = pd.DataFrame({\n",
    "    'Order ID': ['1001', '1002', '1003'],\n",
    "    'Quantity': ['5', '1', '10'],\n",
    "    'Price': ['10.99', '5.00', '1.25'],\n",
    "    'Category': ['Fruit', 'Fruit', 'Veg']\n",
    "})\n",
    "print(\"\\n--- 17. Dirty DataFrame ---\")\n",
    "df_dirty.info()\n",
    "\n",
    "# Example 10: Define the data types\n",
    "# 'Order ID' should stay text, 'Quantity' should be int\n",
    "# 'Price' should be float, 'Category' should be category\n",
    "type_map = {\n",
    "    'Quantity': int,\n",
    "    'Price': float,\n",
    "    'Category': 'category'\n",
    "}\n",
    "\n",
    "# Example 11: Clean the DataFrame\n",
    "df_clean = df_dirty.astype(type_map)\n",
    "\n",
    "print(\"\\n--- 18. Cleaned DataFrame ---\")\n",
    "df_clean.info()\n",
    "\n",
    "# Example 12: Prove it works\n",
    "print(f\"\\nTotal quantity: {df_clean['Quantity'].sum()}\")\n",
    "print(f\"Total price: {df_clean['Price'].sum()}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 17. Dirty DataFrame ---\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 3 entries, 0 to 2\n",
    "Data columns (total 4 columns):\n",
    " #   Column    Non-Null Count  Dtype \n",
    "---  ------    --------------  ----- \n",
    " 0   Order ID  3 non-null      object\n",
    " 1   Quantity  3 non-null      object\n",
    " 2   Price     3 non-null      object\n",
    " 3   Category  3 non-null      object\n",
    "dtypes: object(4)\n",
    "memory usage: 224.0+ bytes\n",
    "\n",
    "--- 18. Cleaned DataFrame ---\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 3 entries, 0 to 2\n",
    "Data columns (total 4 columns):\n",
    " #   Column    Non-Null Count  Dtype   \n",
    "---  ------    --------------  -----   \n",
    " 0   Order ID  3 non-null      object  \n",
    " 1   Quantity  3 non-null      int64   \n",
    " 2   Price     3 non-null      float64 \n",
    " 3   Category  3 non-null      category\n",
    "dtypes: category(1), float64(1), int64(1), object(1)\n",
    "memory usage: 319.0 bytes\n",
    "\n",
    "Total quantity: 16\n",
    "Total price: 17.24\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "We used a `type_map` dictionary to clean the three columns that were wrong. `Order ID` was correctly left as an `object`. We can now perform math on `Quantity` and `Price`, and `Category` is memory-efficient.\n",
    "\n",
    "-----\n",
    "\n",
    "### 5\\. Common Mistakes / Pitfalls\n",
    "\n",
    "**Mistake 13: `ValueError` from a \"dirty\" entry**\n",
    "This is the single most common problem with `.astype()`.\n",
    "\n",
    "```python\n",
    "s_dirty = pd.Series(['1', '2', '3-Oops', '4'])\n",
    "print(\"\\n--- 19. Dirty Series ---\")\n",
    "print(s_dirty)\n",
    "\n",
    "# Wrong code\n",
    "try:\n",
    "    s_dirty.astype(int)\n",
    "except ValueError as e:\n",
    "    print(f\"\\n--- 20. Error ---\")\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "`ValueError: invalid literal for int() with base 10: '3-Oops'`\n",
    "**Why it happens:** `.astype(int)` is an \"all or nothing\" operation. The instant it found `'3-Oops'`, which it couldn't convert to a number, it failed and stopped.\n",
    "**Correction:** This is where `.astype()` is the *wrong tool*. You **must** use `pd.to_numeric(s, errors='coerce')` for this, which we will cover next.\n",
    "\n",
    "**Mistake 14: `astype(bool)` on text**\n",
    "(See Example 8) The string `'False'` converts to `True`, which is almost never what you want.\n",
    "\n",
    "**Mistake 15: Forgetting to re-assign**\n",
    "`.astype()` returns a *copy*. It does not change your original DataFrame.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': ['1', '2']})\n",
    "print(\"\\n--- 21. Original ---\")\n",
    "print(f\"Dtype: {df['A'].dtype}\")\n",
    "\n",
    "# Wrong code\n",
    "df.astype({'A': int}) # This creates a copy, then throws it away\n",
    "\n",
    "print(\"\\n--- 22. After (Still object!) ---\")\n",
    "print(f\"Dtype: {df['A'].dtype}\")\n",
    "\n",
    "# Example 16: Corrected code\n",
    "df_clean = df.astype({'A': int})\n",
    "print(\"\\n--- 23. Corrected (New DF) ---\")\n",
    "print(f\"Dtype: {df_clean['A'].dtype}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 21. Original ---\n",
    "Dtype: object\n",
    "\n",
    "--- 22. After (Still object!) ---\n",
    "Dtype: object\n",
    "\n",
    "--- 23. Corrected (New DF) ---\n",
    "Dtype: int64\n",
    "```\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Type conversions second subtopic: `pd.to_numeric()`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "`pd.to_numeric()` is your specialized tool for converting a Series (or column) to a **numeric type** (like `int64` or `float64`). Unlike the all-purpose `.astype()`, `pd.to_numeric()` is *smarter* and *safer* when dealing with \"dirty\" data that might contain non-numeric values.\n",
    "\n",
    "Its killer feature is the `errors='coerce'` parameter. This tells Pandas: \"Try to make this column numeric. If you find a value you can't convert (like `'hello'` or `'3-Oops'`), don't stop and raise an error. Just *coerce* it into a `NaN` (Not a Number) value, and keep going.\"\n",
    "\n",
    "**How It Works in Memory**: `pd.to_numeric()` is a function, not a method, so you call it as `pd.to_numeric(s)`. It *always* returns a **new** `pd.Series` (a copy) with the converted data. It inspects each string value: if it looks like an integer, it's parsed as an integer; if it has a decimal, it's parsed as a float. If `errors='coerce'` is used, a `NaN` value may be introduced, which will often force the *entire* Series to become `float64` (since `NaN` is a float).\n",
    "\n",
    "**When to Use This**:\n",
    "\n",
    "  * **This is the preferred tool** for converting a text (`object`) column to numbers when you *suspect* there might be bad data.\n",
    "  * Use this when your column has values like `'$1,200'`, `'50%'`, or `'--'` mixed in with clean numbers.\n",
    "  * You *must* use this (with `errors='coerce'`) *before* you can use `.astype(int)`, as it will clean out the non-numeric \"gunk\" that would cause `.astype()` to fail.\n",
    "\n",
    "-----\n",
    "\n",
    "### 0\\. Syntax & Parameters (MUST COME FIRST)\n",
    "\n",
    "`pd.to_numeric()` is a top-level Pandas function, *not* a DataFrame method.\n",
    "\n",
    "```python\n",
    "pandas.to_numeric(arg, errors='raise', downcast=None)\n",
    "```\n",
    "\n",
    "  * **`arg`** (argument)\n",
    "      * **What it does:** The object you want to convert. This is typically a `pd.Series` (or a single column from a DataFrame, like `df['col']`).\n",
    "      * **Default value:** (Required)\n",
    "      * **When you would use it:** You *always* provide this. `pd.to_numeric(df['my_column'])`\n",
    "  * **`errors`**\n",
    "      * **What it does:** This is the most important parameter. It tells Pandas what to do when it finds a value it can't convert.\n",
    "      * **Default value:** `'raise'`\n",
    "      * **When you would use it:**\n",
    "          * `'raise'`: The default. It will stop your code and show a `ValueError` if it finds a bad value (like `'hello'`). This is the same behavior as `.astype()`.\n",
    "          * `'coerce'`: **This is the killer feature.** It will replace any bad value (like `'hello'`) with `NaN`. This allows your code to run without stopping.\n",
    "          * `'ignore'`: This is the *least* useful. It will silently fail on bad values, leaving them as-is in the original `object` column (so the whole column remains `object`).\n",
    "  * **`downcast`**\n",
    "      * **What it does:** An advanced memory-saving feature. If your data is all numbers, this will try to \"downcast\" them to the smallest possible numeric type.\n",
    "      * **Default value:** `None`\n",
    "      * **When you would use it:**\n",
    "          * `downcast='integer'`: If your data is `[1.0, 2.0, 3.0]`, it will be converted to `int64`.\n",
    "          * `downcast='float'`: Will try to use `float32` instead of `float64`.\n",
    "      * **What happens if you don't specify it:** It will use the standard `int64` or `float64`, which is fine.\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. Basic Example\n",
    "\n",
    "Let's see the most important use: `errors='coerce'`.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example 1: A dirty Series with a non-numeric string\n",
    "s_dirty = pd.Series(['1', '2', '3-Oops', '4'])\n",
    "print(\"--- 1. Dirty Series ---\")\n",
    "print(s_dirty)\n",
    "print(f\"Dtype: {s_dirty.dtype}\")\n",
    "\n",
    "# Example 2: Using .astype() (This will FAIL)\n",
    "try:\n",
    "    s_dirty.astype(int)\n",
    "except ValueError as e:\n",
    "    print(f\"\\n--- 2. .astype(int) FAILS ---\")\n",
    "    print(e)\n",
    "\n",
    "# Example 3: Using pd.to_numeric() with errors='coerce'\n",
    "s_clean = pd.to_numeric(s_dirty, errors='coerce')\n",
    "print(\"\\n--- 3. pd.to_numeric(errors='coerce') WORKS ---\")\n",
    "print(s_clean)\n",
    "print(f\"Dtype: {s_clean.dtype}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 1. Dirty Series ---\n",
    "0         1\n",
    "1         2\n",
    "2    3-Oops\n",
    "3         4\n",
    "dtype: object\n",
    "Dtype: object\n",
    "\n",
    "--- 2. .astype(int) FAILS ---\n",
    "invalid literal for int() with base 10: '3-Oops'\n",
    "\n",
    "--- 3. pd.to_numeric(errors='coerce') WORKS ---\n",
    "0    1.0\n",
    "1    2.0\n",
    "2    NaN\n",
    "3    4.0\n",
    "dtype: float64\n",
    "Dtype: float64\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "This is the perfect comparison. `.astype(int)` saw `'3-Oops'` and failed instantly. `pd.to_numeric(errors='coerce')` saw `'3-Oops'`, didn't panic, and quietly replaced it with `NaN` (Not a Number). Note that the `dtype` is now `float64`, because `NaN` is a float.\n",
    "\n",
    "-----\n",
    "\n",
    "### 2\\. Intermediate Example\n",
    "\n",
    "You can combine `to_numeric` with other methods to clean data.\n",
    "\n",
    "**Example 4: A common data-cleaning workflow**\n",
    "Data often has `$` and `,` symbols. `to_numeric` can't handle them *unless* you clean them first.\n",
    "\n",
    "```python\n",
    "s_prices = pd.Series(['$1,200.50', '$50.00', 'No Data', '$100.00'])\n",
    "print(\"--- 4. Price Series (very dirty) ---\")\n",
    "print(s_prices)\n",
    "\n",
    "# Example 5: Clean the strings first\n",
    "s_cleaned_strings = s_prices.str.replace('$', '').str.replace(',', '')\n",
    "print(\"\\n--- 5. After replacing '$' and ',' ---\")\n",
    "print(s_cleaned_strings)\n",
    "\n",
    "# Example 6: NOW use to_numeric\n",
    "s_numeric_prices = pd.to_numeric(s_cleaned_strings, errors='coerce')\n",
    "print(\"\\n--- 6. After pd.to_numeric(errors='coerce') ---\")\n",
    "print(s_numeric_prices)\n",
    "print(f\"Total value: {s_numeric_prices.sum()}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 4. Price Series (very dirty) ---\n",
    "0    $1,200.50\n",
    "1       $50.00\n",
    "2      No Data\n",
    "3     $100.00\n",
    "dtype: object\n",
    "\n",
    "--- 5. After replacing '$' and ',' ---\n",
    "0    1200.50\n",
    "1      50.00\n",
    "2    No Data\n",
    "3     100.00\n",
    "dtype: object\n",
    "\n",
    "--- 6. After pd.to_numeric(errors='coerce') ---\n",
    "0    1200.5\n",
    "1      50.0\n",
    "2       NaN\n",
    "3     100.0\n",
    "dtype: float64\n",
    "Total value: 1350.5\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "This is a standard 2-step process.\n",
    "\n",
    "1.  Use `.str.replace()` to remove non-numeric characters like `$` and `,`.\n",
    "2.  Use `pd.to_numeric(errors='coerce')` to convert the cleaned strings to numbers, which neatly handles the remaining bad entries like `'No Data'`.\n",
    "\n",
    "**Example 7: Using `downcast='integer'`**\n",
    "This is a memory-saving trick.\n",
    "\n",
    "```python\n",
    "s_floats = pd.Series(['1.0', '2.0', '3.0'])\n",
    "print(\"\\n--- 7. Series of float-strings ---\")\n",
    "print(s_floats)\n",
    "\n",
    "# Example 8: Standard conversion\n",
    "s_float_std = pd.to_numeric(s_floats)\n",
    "print(f\"\\n--- 8. Standard conversion (Dtype: {s_float_std.dtype}) ---\")\n",
    "print(s_float_std)\n",
    "\n",
    "# Example 9: Downcast to integer\n",
    "s_downcast = pd.to_numeric(s_floats, downcast='integer')\n",
    "print(f\"\\n--- 9. Downcast to integer (Dtype: {s_downcast.dtype}) ---\")\n",
    "print(s_downcast)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 7. Series of float-strings ---\n",
    "0    1.0\n",
    "1    2.0\n",
    "2    3.0\n",
    "dtype: object\n",
    "\n",
    "--- 8. Standard conversion (Dtype: float64) ---\n",
    "0    1.0\n",
    "1    2.0\n",
    "2    3.0\n",
    "dtype: float64\n",
    "\n",
    "--- 9. Downcast to integer (Dtype: int64) ---\n",
    "0    1\n",
    "1    2\n",
    "2    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "The standard `to_numeric` saw the `.` and kept them as `float64`. By adding `downcast='integer'`, we told Pandas: \"If possible, after converting, please try to store these as integers.\" It was possible, so it stored them as `int64`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 3\\. Advanced or Tricky Case\n",
    "\n",
    "What happens if you *want* `int` but `coerce` gives you `NaN`?\n",
    "\n",
    "**Example 10: The `coerce` + `fillna` + `astype` chain**\n",
    "This is the full \"pro\" pattern to get a clean `int` column from dirty data.\n",
    "\n",
    "```python\n",
    "s_dirty = pd.Series(['1', '2', '3-Oops', '4', np.nan])\n",
    "print(\"--- 10. Dirty Series with NaN ---\")\n",
    "print(s_dirty)\n",
    "\n",
    "# Step 1: Force all non-numeric to NaN\n",
    "s_coerced = pd.to_numeric(s_dirty, errors='coerce')\n",
    "print(\"\\n--- 11. Step 1: Coerced (float with NaN) ---\")\n",
    "print(s_coerced)\n",
    "\n",
    "# Step 2: Fill the NaNs with a value (e.g., 0)\n",
    "s_filled = s_coerced.fillna(0)\n",
    "print(\"\\n--- 12. Step 2: Filled (float with 0.0) ---\")\n",
    "print(s_filled)\n",
    "\n",
    "# Step 3: Now that it's safe (no NaNs), convert to int\n",
    "s_final_int = s_filled.astype(int)\n",
    "print(\"\\n--- 13. Step 3: Final (int) ---\")\n",
    "print(s_final_int)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 10. Dirty Series with NaN ---\n",
    "0         1\n",
    "1         2\n",
    "2    3-Oops\n",
    "3         4\n",
    "4       NaN\n",
    "dtype: object\n",
    "\n",
    "--- 11. Step 1: Coerced (float with NaN) ---\n",
    "0    1.0\n",
    "1    2.0\n",
    "2    NaN\n",
    "3    4.0\n",
    "4    NaN\n",
    "dtype: float64\n",
    "\n",
    "--- 12. Step 2: Filled (float with 0.0) ---\n",
    "0    1.0\n",
    "1    2.0\n",
    "2    0.0\n",
    "3    4.0\n",
    "4    0.0\n",
    "dtype: float64\n",
    "\n",
    "--- 13. Step 3: Final (int) ---\n",
    "0    1\n",
    "1    2\n",
    "2    0\n",
    "3    4\n",
    "4    0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "This 3-step chain is one of the most important patterns in data cleaning:\n",
    "\n",
    "1.  `pd.to_numeric(s, errors='coerce')` turns all \"bad\" strings (`'3-Oops'`) into `NaN`.\n",
    "2.  `.fillna(0)` replaces all `NaN`s (both the original `np.nan` and the new ones) with `0`.\n",
    "3.  `.astype(int)` safely converts the all-float, no-`NaN` Series into a clean integer Series.\n",
    "\n",
    "**Example 11: Applying to a DataFrame column**\n",
    "You *don't* call `pd.to_numeric(df)`. You call it on the *column* and re-assign it.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': [1, 2], 'B': ['5', '6-Bad']})\n",
    "print(\"\\n--- 14. Original DataFrame ---\")\n",
    "df.info()\n",
    "\n",
    "# Apply the function to the 'B' column\n",
    "df['B'] = pd.to_numeric(df['B'], errors='coerce')\n",
    "\n",
    "print(\"\\n--- 15. After applying to 'B' ---\")\n",
    "df.info()\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 14. Original DataFrame ---\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 2 entries, 0 to 1\n",
    "Data columns (total 2 columns):\n",
    " #   Column  Non-Null Count  Dtype \n",
    "---  ------  --------------  ----- \n",
    " 0   A       2 non-null      int64 \n",
    " 1   B       2 non-null      object\n",
    "dtypes: int64(1), object(1)\n",
    "memory usage: 160.0+ bytes\n",
    "\n",
    "--- 15. After applying to 'B' ---\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 2 entries, 0 to 1\n",
    "Data columns (total 2 columns):\n",
    " #   Column  Non-Null Count  Dtype  \n",
    "---  ------  --------------  -----  \n",
    " 0   A       2 non-null      int64  \n",
    " 1   B       1 non-null      float64\n",
    "dtypes: float64(1), int64(1)\n",
    "memory usage: 160.0+ bytes\n",
    "   A    B\n",
    "0  1  5.0\n",
    "1  2  NaN\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### 4\\. Real-World Use Case\n",
    "\n",
    "**Example 12: Cleaning a \"Percentage\" column**\n",
    "You load a column that looks like `95%`, `90%`, `80.5%`.\n",
    "\n",
    "```python\n",
    "s_percent = pd.Series(['95%', '90%', '80.5%', 'N/A'])\n",
    "print(\"--- 16. Original Percentage Series ---\")\n",
    "print(s_percent)\n",
    "\n",
    "# Example 13: Clean and convert\n",
    "# Step 1: Remove the '%'\n",
    "s_cleaned = s_percent.str.replace('%', '')\n",
    "print(\"\\n--- 17. After removing '%' ---\")\n",
    "print(s_cleaned)\n",
    "\n",
    "# Step 2: Convert, coercing 'N/A'\n",
    "s_numeric = pd.to_numeric(s_cleaned, errors='coerce')\n",
    "print(\"\\n--- 18. After to_numeric ---\")\n",
    "print(s_numeric)\n",
    "\n",
    "# Example 14: Bonus step - convert to decimal\n",
    "s_decimal = s_numeric / 100\n",
    "print(\"\\n--- 19. As decimal ---\")\n",
    "print(s_decimal)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 16. Original Percentage Series ---\n",
    "0      95%\n",
    "1      90%\n",
    "2    80.5%\n",
    "3      N/A\n",
    "dtype: object\n",
    "\n",
    "--- 17. After removing '%' ---\n",
    "0      95\n",
    "1      90\n",
    "2    80.5\n",
    "3     N/A\n",
    "dtype: object\n",
    "\n",
    "--- 18. After to_numeric ---\n",
    "0    95.0\n",
    "1    90.0\n",
    "2    80.5\n",
    "3     NaN\n",
    "dtype: float64\n",
    "\n",
    "--- 19. As decimal ---\n",
    "0    0.950\n",
    "1    0.900\n",
    "2    0.805\n",
    "3      NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "This is a perfect, common workflow. `to_numeric` can't handle `%`, so we remove it. Then `to_numeric` *can* handle `'N/A'` by coercing it to `NaN`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 5\\. Common Mistakes / Pitfalls\n",
    "\n",
    "**Mistake 15: Using `errors='ignore'`**\n",
    "This is the most dangerous and useless option.\n",
    "\n",
    "```python\n",
    "s_dirty = pd.Series(['1', '2', '3-Oops', '4'])\n",
    "print(\"\\n--- 20. Dirty Series ---\")\n",
    "print(s_dirty)\n",
    "\n",
    "# Wrong code (using 'ignore')\n",
    "s_ignored = pd.to_numeric(s_dirty, errors='ignore')\n",
    "print(\"\\n--- 21. After errors='ignore' ---\")\n",
    "print(s_ignored)\n",
    "print(f\"Dtype: {s_ignored.dtype}\")\n",
    "print(f\"Sum (fails): {s_ignored.sum()}\")\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "\n",
    "```\n",
    "--- 20. Dirty Series ---\n",
    "0         1\n",
    "1         2\n",
    "2    3-Oops\n",
    "3         4\n",
    "dtype: object\n",
    "\n",
    "--- 21. After errors='ignore' ---\n",
    "0         1\n",
    "1         2\n",
    "2    3-Oops\n",
    "3         4\n",
    "dtype: object\n",
    "Dtype: object\n",
    "Sum (fails): 123-Oops4\n",
    "```\n",
    "\n",
    "**Why it happens:** `errors='ignore'` means \"If you find a bad value, *just stop* and return the original object.\" It didn't convert *anything*. The `dtype` is still `object`. Use `errors='coerce'`.\n",
    "\n",
    "**Mistake 16: Forgetting to re-assign**\n",
    "Like `.astype()`, `pd.to_numeric()` returns a *new Series*.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'A': ['1', '2-Bad']})\n",
    "print(\"\\n--- 22. Original DF ---\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Wrong code\n",
    "pd.to_numeric(df['A'], errors='coerce') # This returns a new Series, but we don't save it\n",
    "\n",
    "print(\"\\n--- 23. After (Still object!) ---\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Example 17: Corrected code\n",
    "df['A'] = pd.to_numeric(df['A'], errors='coerce')\n",
    "print(\"\\n--- 24. Corrected ---\")\n",
    "print(df.dtypes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 22. Original DF ---\n",
    "A    object\n",
    "dtype: object\n",
    "\n",
    "--- 23. After (Still object!) ---\n",
    "A    object\n",
    "dtype: object\n",
    "\n",
    "--- 24. Corrected ---\n",
    "A    float64\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "\n",
    "# Type conversions third subtopic: `pd.to_datetime()`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "`pd.to_datetime()` is your specialized tool for converting strings or numbers that *represent dates* into a true **datetime object**. This is one of the most important steps in data cleaning.\n",
    "\n",
    "When you load data, dates are almost always read as simple text (`object`), like `'2025-11-17'`. You can't do date-based operations on text (e.g., \"find all sales from last week,\" or \"group by month\"). `pd.to_datetime()` is the function that parses this text and converts it into a special `datetime64[ns]` object, which is a data type that Pandas understands as a date and time. This \"unlocks\" all of a DataFrame's powerful time-series abilities.\n",
    "\n",
    "**How It Works in Memory**: `pd.to_datetime()` is a highly optimized function that parses strings. It creates a **new** `pd.Series` (a copy) in memory. The data type of this new Series will be `datetime64[ns]`, which means it stores each date as a 64-bit integer representing the number of nanoseconds since a specific point in time (1970-01-01, the \"Unix epoch\"). This is what makes date calculations (like finding the difference between two dates) extremely fast.\n",
    "\n",
    "**When to Use This**:\n",
    "\n",
    "  * **This is the preferred tool** for converting any date-like column (`object`) into a `datetime64` type.\n",
    "  * Use this when your dates are in a standard format (`'2025-11-17'`) that Pandas can guess.\n",
    "  * You *must* use this with the `format` parameter when your dates are in a weird or non-standard format (`'11/17/2025'`, `'17-Nov-2025'`).\n",
    "  * Use this with `errors='coerce'` to handle unparseable dates (like `'hello'`) by turning them into `NaT` (Not a Time).\n",
    "\n",
    "-----\n",
    "\n",
    "### 0\\. Syntax & Parameters (MUST COME FIRST)\n",
    "\n",
    "`pd.to_datetime()` is a top-level Pandas function.\n",
    "\n",
    "```python\n",
    "pandas.to_datetime(arg, errors='raise', format=None, infer_datetime_format=False, ...)\n",
    "```\n",
    "\n",
    "  * **`arg`** (argument)\n",
    "      * **What it does:** The object you want to convert. This is typically a `pd.Series` (e.g., `df['col']`), a list, or even a full DataFrame (if you're assembling dates from columns).\n",
    "      * **Default value:** (Required)\n",
    "      * **When you would use it:** You *always* provide this. `pd.to_datetime(df['date_column'])`\n",
    "  * **`errors`**\n",
    "      * **What it does:** Tells Pandas what to do when it finds a date string it *cannot* parse.\n",
    "      * **Default value:** `'raise'`\n",
    "      * **When you would use it:**\n",
    "          * `'raise'`: The default. It will stop your code and show a `ValueError` if it finds a bad date (like `'hello'`).\n",
    "          * `'coerce'`: **This is the killer feature.** It will replace any bad/unparseable date (like `'hello'` or `'2025-02-30'`) with `NaT` (Not a Time), which is the `NaN` equivalent for datetimes.\n",
    "          * `'ignore'`: This is the *least* useful. It will silently fail on bad values, returning the original `object` Series.\n",
    "  * **`format`**\n",
    "      * **What it does:** This is the *second* most important parameter. It's a \"format string\" that tells Pandas *exactly* how your dates are structured. (e.g., `%m/%d/%Y` tells Pandas to look for \"month/day/4-digit-year\").\n",
    "      * **Default value:** `None`\n",
    "      * **When you would use it:** You *must* use this when your dates are in a non-standard format. If you don't, Pandas will try to guess, which can be slow or (worse) *wrong*.\n",
    "      * **What happens if you don't specify it:** Pandas will try to automatically `infer_datetime_format`. This is often successful for standard formats but will fail on ambiguous ones (is `01/02/2025` Jan 2nd or Feb 1st?).\n",
    "  * **`infer_datetime_format`**\n",
    "      * **What it does:** If `True` (and `format` is `None`), Pandas will try to \"learn\" the format from the first non-`NaN` date string.\n",
    "      * **Default value:** `False`\n",
    "      * **When you would use it:** Set this to `True` for a **massive speed boost** if your dates are in a *consistent*, standard format.\n",
    "      * **What happens if you don't specify it:** Pandas will test several formats, which is slower.\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. Basic Example\n",
    "\n",
    "Let's convert a standard, clean list of date strings.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example 1: A Series of ISO-formatted strings (standard)\n",
    "s_dates = pd.Series(['2025-01-01', '2025-01-02', '2025-01-03'])\n",
    "print(\"--- 1. Original (text/object) ---\")\n",
    "print(s_dates)\n",
    "print(f\"Dtype: {s_dates.dtype}\")\n",
    "\n",
    "# Example 2: Convert using pd.to_datetime\n",
    "s_datetime = pd.to_datetime(s_dates)\n",
    "print(\"\\n--- 2. After pd.to_datetime() ---\")\n",
    "print(s_datetime)\n",
    "print(f\"Dtype: {s_datetime.dtype}\")\n",
    "\n",
    "# Example 3: What we've \"unlocked\" (the .dt accessor)\n",
    "print(\"\\n--- 3. Unlocked .dt accessor ---\")\n",
    "print(f\"Day names: {s_datetime.dt.day_name().tolist()}\")\n",
    "print(f\"Months: {s_datetime.dt.month.tolist()}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 1. Original (text/object) ---\n",
    "0    2025-01-01\n",
    "1    2025-01-02\n",
    "2    2025-01-03\n",
    "dtype: object\n",
    "Dtype: object\n",
    "\n",
    "--- 2. After pd.to_datetime() ---\n",
    "0   2025-01-01\n",
    "1   2025-01-02\n",
    "2   2025-01-03\n",
    "dtype: datetime64[ns]\n",
    "Dtype: datetime64[ns]\n",
    "\n",
    "--- 3. Unlocked .dt accessor ---\n",
    "Day names: ['Wednesday', 'Thursday', 'Friday']\n",
    "Months: [1, 1, 1]\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Pandas automatically recognized the standard `'YYYY-MM-DD'` format and converted the `object` Series to a `datetime64[ns]` Series. This \"unlocked\" the `.dt` accessor, which lets us instantly pull out the day name, month, year, etc.\n",
    "\n",
    "**Example 4: Handling mixed standard formats**\n",
    "Pandas is smart enough to guess many common formats.\n",
    "\n",
    "```python\n",
    "s_mixed = pd.Series(['2025-01-01', '02/01/2025', 'Jan 3, 2025'])\n",
    "print(\"\\n--- 4. Mixed (but standard) formats ---\")\n",
    "print(pd.to_datetime(s_mixed))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 4. Mixed (but standard) formats ---\n",
    "0   2025-01-01\n",
    "1   2025-02-01\n",
    "2   2025-01-03\n",
    "dtype: datetime64[ns]\n",
    "```\n",
    "\n",
    "**Explanation:** Pandas correctly (in this US-based-logic case) inferred all three formats. *Warning:* `'02/01/2025'` is ambiguous (Feb 1st or Jan 2nd?). This is why `format` is safer.\n",
    "\n",
    "-----\n",
    "\n",
    "### 2\\. Intermediate Example\n",
    "\n",
    "Using the `format` parameter for non-standard, ambiguous dates.\n",
    "\n",
    "**Example 5: The Ambiguity Problem**\n",
    "Is `'05-06-2025'` May 6th or June 5th?\n",
    "\n",
    "```python\n",
    "s_ambiguous = pd.Series(['05-06-2025', '07-08-2025'])\n",
    "print(\"--- 5. Ambiguous Dates ---\")\n",
    "print(pd.to_datetime(s_ambiguous))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 5. Ambiguous Dates ---\n",
    "0   2025-05-06\n",
    "1   2025-07-08\n",
    "dtype: datetime64[ns]\n",
    "```\n",
    "\n",
    "**Explanation:** By default, Pandas (and the underlying `dateutil` library) \"guessed\" `MM-DD-YYYY`. This is dangerous if your data is actually from Europe (`DD-MM-YYYY`).\n",
    "\n",
    "**Example 6: Using `format` to be explicit (Day-First)**\n",
    "This is the *safe* way. `format` strings tell Pandas exactly what to look for:\n",
    "\n",
    "  * `%d` = day\n",
    "  * `%m` = month\n",
    "  * `%Y` = 4-digit year\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "s_ambiguous = pd.Series(['05-06-2025', '07-08-2025'])\n",
    "# Tell Pandas to read it as Day-Month-Year\n",
    "dt_dayfirst = pd.to_datetime(s_ambiguous, format='%d-%m-%Y')\n",
    "print(\"\\n--- 6. With format='%d-%m-%Y' (Day-First) ---\")\n",
    "print(dt_dayfirst)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 6. With format='%d-%m-%Y' (Day-First) ---\n",
    "0   2025-06-05\n",
    "1   2025-08-07\n",
    "dtype: datetime64[ns]\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "By providing the `format`, we forced Pandas to read `'05-06-2025'` as June 5th, not May 6th. This is robust and correct.\n",
    "\n",
    "**Example 7: Using `format` for other weird strings**\n",
    "\n",
    "```python\n",
    "s_weird = pd.Series(['Nov 17, 2025, 03:30 PM'])\n",
    "# %b = Month abbrev, %d = day, %Y = year\n",
    "# %I = 12-hr, %M = minute, %p = AM/PM\n",
    "dt_weird = pd.to_datetime(s_weird, format='%b %d, %Y, %I:%M %p')\n",
    "print(\"\\n--- 7. Parsing a complex string ---\")\n",
    "print(dt_weird)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 7. Parsing a complex string ---\n",
    "0   2025-11-17 15:30:00\n",
    "dtype: datetime64[ns]\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### 3\\. Advanced or Tricky Case\n",
    "\n",
    "Using `errors` to handle bad data.\n",
    "\n",
    "**Example 8: `errors='raise'` (The Default)**\n",
    "This is what happens when a `format` is specified but the data doesn't match.\n",
    "\n",
    "```python\n",
    "s_dirty = pd.Series(['11-17-2025', '11-18-2025', 'NOT A DATE', '11-20-2025'])\n",
    "print(\"\\n--- 8. Dirty Date Series ---\")\n",
    "print(s_dirty)\n",
    "\n",
    "try:\n",
    "    # Use default errors='raise'\n",
    "    pd.to_datetime(s_dirty, format='%m-%d-%Y')\n",
    "except ValueError as e:\n",
    "    print(f\"\\n--- 9. errors='raise' FAILS ---\")\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 8. Dirty Date Series ---\n",
    "0    11-17-2025\n",
    "1    11-18-2025\n",
    "2    NOT A DATE\n",
    "3    11-20-2025\n",
    "dtype: object\n",
    "\n",
    "--- 9. errors='raise' FAILS ---\n",
    "time data 'NOT A DATE' does not match format '%m-%d-%Y' (match)\n",
    "```\n",
    "\n",
    "**Example 10: `errors='coerce'` (The Fix)**\n",
    "This is the *best* way to handle bad data.\n",
    "\n",
    "```python\n",
    "# Use errors='coerce' to turn bad dates into NaT\n",
    "dt_coerced = pd.to_datetime(s_dirty, format='%m-%d-%Y', errors='coerce')\n",
    "print(\"\\n--- 10. errors='coerce' WORKS ---\")\n",
    "print(dt_coerced)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 10. errors='coerce' WORKS ---\n",
    "0   2025-11-17\n",
    "1   2025-11-18\n",
    "2          NaT\n",
    "3   2025-11-20\n",
    "dtype: datetime64[ns]\n",
    "```\n",
    "\n",
    "**Explanation:** `errors='coerce'` is the perfect tool. It converted the good dates, saw `'NOT A DATE'`, and converted it to `NaT` (Not a Time) without stopping.\n",
    "\n",
    "**Example 11: `errors='ignore'` (The Weird One)**\n",
    "This is almost never what you want.\n",
    "\n",
    "```python\n",
    "# Use errors='ignore'\n",
    "dt_ignored = pd.to_datetime(s_dirty, format='%m-%d-%Y', errors='ignore')\n",
    "print(\"\\n--- 11. errors='ignore' (returns object) ---\")\n",
    "print(dt_ignored)\n",
    "print(f\"Dtype: {dt_ignored.dtype}\")\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 11. errors='ignore' (returns object) ---\n",
    "0    11-17-2025\n",
    "1    11-18-2025\n",
    "2    NOT A DATE\n",
    "3    11-20-2025\n",
    "dtype: object\n",
    "Dtype: object\n",
    "```\n",
    "\n",
    "**Explanation:** `errors='ignore'` saw the bad value and just *gave up*, returning the *original object-type Series*.\n",
    "\n",
    "-----\n",
    "\n",
    "### 4\\. Real-World Use Case\n",
    "\n",
    "**Example 12: Assembling a date from multiple columns**\n",
    "This is a *very* common scenario.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'year': [2025, 2026, 2025],\n",
    "    'month': [1, 5, 12],\n",
    "    'day': [1, 15, 31],\n",
    "    'sales': [100, 200, 300]\n",
    "})\n",
    "print(\"--- 12. Original DataFrame with cols ---\")\n",
    "print(df)\n",
    "\n",
    "# Example 13: Pass a DataFrame to pd.to_datetime\n",
    "# It will find 'year', 'month', 'day'\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "print(\"\\n--- 13. After assembling date ---\")\n",
    "print(df)\n",
    "df.info()\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 12. Original DataFrame with cols ---\n",
    "   year  month  day  sales\n",
    "0  2025      1    1    100\n",
    "1  2026      5   15    200\n",
    "2  2025     12   31    300\n",
    "\n",
    "--- 13. After assembling date ---\n",
    "   year  month  day  sales       date\n",
    "0  2025      1    1    100 2025-01-01\n",
    "1  2026      5   15    200 2026-05-15\n",
    "2  2025     12   31    300 2025-12-31\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 3 entries, 0 to 2\n",
    "Data columns (total 5 columns):\n",
    " #   Column  Non-Null Count  Dtype         \n",
    "---  ------  --------------  -----         \n",
    " 0   year    3 non-null      int64         \n",
    " 1   month   3 non-null      int64         \n",
    " 2   day     3 non-null      int64         \n",
    " 3   sales   3 non-null      int64         \n",
    " 4   date    3 non-null      datetime64[ns]\n",
    "dtypes: datetime64[ns](1), int64(4)\n",
    "memory usage: 248.0 bytes\n",
    "```\n",
    "\n",
    "**Explanation:** `pd.to_datetime()` is smart. When you pass it a DataFrame containing columns with standard names (`year`, `month`, `day`, `hour`, etc.), it automatically assembles them into a single datetime column.\n",
    "\n",
    "**Example 14: Converting Unix timestamps**\n",
    "\n",
    "```python\n",
    "s_epoch = pd.Series([1731846000, 1731932400])\n",
    "print(\"\\n--- 14. Unix Epoch (int) ---\")\n",
    "print(s_epoch)\n",
    "\n",
    "# Tell it the unit is 'seconds'\n",
    "dt_epoch = pd.to_datetime(s_epoch, unit='s')\n",
    "print(\"\\n--- 15. Converted from Unix ---\")\n",
    "print(dt_epoch)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 14. Unix Epoch (int) ---\n",
    "0    1731846000\n",
    "1    1731932400\n",
    "dtype: int64\n",
    "\n",
    "--- 15. Converted from Unix ---\n",
    "0   2024-11-17 12:20:00\n",
    "1   2024-11-18 12:20:00\n",
    "dtype: datetime64[ns]\n",
    "```\n",
    "\n",
    "*(Self-correction: The provided timestamp `1731846000` is for 2024, not 2025. The output is correct based on the input.)*\n",
    "\n",
    "-----\n",
    "\n",
    "### 5\\. Common Mistakes / Pitfalls\n",
    "\n",
    "**Mistake 15: The `format` string is *wrong***\n",
    "This is the \\#1 error. Your `format` string *must exactly match* your data.\n",
    "\n",
    "```python\n",
    "s_data = pd.Series(['17/11/2025']) # Day/Month/Year\n",
    "print(\"\\n--- 16. Data (D/M/Y) ---\")\n",
    "print(s_data)\n",
    "\n",
    "# Wrong code\n",
    "try:\n",
    "    # We told it Month/Day/Year\n",
    "    pd.to_datetime(s_data, format='%m/%d/%Y')\n",
    "except ValueError as e:\n",
    "    print(f\"\\n--- 17. Error: Format mismatch ---\")\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "`ValueError: time data '17/11/2025' does not match format '%m/%d/%Y' (match)`\n",
    "**Why it happens:** It was looking for a Month (`%m`), but `17` is not a valid month.\n",
    "**Example 18: Corrected code:**\n",
    "\n",
    "```python\n",
    "# Correct code\n",
    "dt_correct = pd.to_datetime(s_data, format='%d/%m/%Y')\n",
    "print(\"\\n--- 18. Corrected format ---\")\n",
    "print(dt_correct)\n",
    "```\n",
    "\n",
    "**Mistake 19: Forgetting to re-assign**\n",
    "`pd.to_datetime()` returns a *new Series*.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'date': ['2025-01-01']})\n",
    "print(\"\\n--- 19. Original (object) ---\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Wrong code\n",
    "pd.to_datetime(df['date']) # This does nothing!\n",
    "\n",
    "print(\"\\n--- 20. After (still object!) ---\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Example 20: Corrected code\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "print(\"\\n--- 21. Corrected ---\")\n",
    "print(df.dtypes)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 19. Original (object) ---\n",
    "date    object\n",
    "dtype: object\n",
    "\n",
    "--- 20. After (still object!) ---\n",
    "date    object\n",
    "dtype: object\n",
    "\n",
    "--- 21. Corrected ---\n",
    "date    datetime64[ns]\n",
    "dtype: object\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
