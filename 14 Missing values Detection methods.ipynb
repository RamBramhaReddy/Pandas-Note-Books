{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4acac2a-0f3d-4bbe-a01f-65308f1e6d36",
   "metadata": {},
   "source": [
    "# 14. Detection methods  first subtopic: `.isna()`, `.notna()`, and `.isnull().sum()`.\n",
    "\n",
    "-----\n",
    "\n",
    "These functions are your \"missing data detectors.\" Their job is to scan your Series or DataFrame and return a `True` or `False` for every single cell, telling you if it's empty or not.\n",
    "\n",
    "  * **`.isna()` / `.isnull()`:** These are **identical**. They ask the question, \"Is this cell missing?\" They return `True` for `np.nan`, `None`, and `pd.NaT` (Not a Time).\n",
    "  * **`.notna()`:** This is the exact **opposite**. It asks, \"Does this cell have a value?\" It returns `True` for any cell that is *not* missing.\n",
    "  * **`.sum()`:** This is a \"chain\" method. When you call `.sum()` on the `True`/`False` mask that `.isna()` gives you, it cleverly counts all the `True` values (since `True` acts like `1` and `False` acts like `0`). `df.isna().sum()` is the standard, fastest way to get a *count* of missing data in every column.\n",
    "\n",
    "**How It Works in Memory**: These methods are highly optimized, vectorized operations. `df.isna()` creates a *new* DataFrame of the exact same shape, but filled with boolean (`True`/`False`) values. This \"boolean mask\" is very memory-light. When you call `.sum()` on this mask, it performs a fast C-level operation to sum the `True` values (as `1`s) down each column, resulting in a small Series of counts.\n",
    "\n",
    "**When to Use This**:\n",
    "\n",
    "  * You will use `df.isna().sum()` **every time** you load a new dataset. It is step \\#1 (along with `df.info()`) for assessing data quality.\n",
    "  * Use `s.isna()` (or `s.notna()`) inside a filter to *find* the actual rows that are missing or complete (e.g., `df[df['email'].notna()]`).\n",
    "  * Use `.isnull()` if you see it in older code; it's just an alias for `.isna()`. The modern standard is `.isna()` and `.notna()`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 0\\. Syntax & Parameters (MUST COME FIRST)\n",
    "\n",
    "These are methods, but they typically have no parameters. They are often chained.\n",
    "\n",
    "```python\n",
    "# On a Series (or DataFrame)\n",
    "series_or_df.isna()\n",
    "\n",
    "# Alias for .isna()\n",
    "series_or_df.isnull()\n",
    "\n",
    "# The opposite of .isna()\n",
    "series_or_df.notna()\n",
    "```\n",
    "\n",
    "  * **Parameters:** These methods take no parameters.\n",
    "  * **Returns:** A Series or DataFrame of the same shape, filled with `True`/`False` values.\n",
    "\n",
    "-----\n",
    "\n",
    "#### Chaining with `.sum()`\n",
    "\n",
    "```python\n",
    "# Get counts for each COLUMN (default axis=0)\n",
    "dataframe.isna().sum()\n",
    "\n",
    "# Get counts for each ROW\n",
    "dataframe.isna().sum(axis=1)\n",
    "```\n",
    "\n",
    "  * **`axis=0` (or `'index')`**: The default. Sums \"down\" the rows, giving a count *per column*.\n",
    "  * **`axis=1` (or `'columns')`**: Sums \"across\" the columns, giving a count *per row*.\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. Basic Example (on a Series)\n",
    "\n",
    "Let's see the three functions in action.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([10, 20, np.nan, 40, None])\n",
    "print(\"--- 1. Original Series ---\")\n",
    "print(s)\n",
    "\n",
    "# Example 1: .isna()\n",
    "# Returns True for np.nan and None\n",
    "print(\"\\n--- 2. Example 1: s.isna() ---\")\n",
    "print(s.isna())\n",
    "\n",
    "# Example 2: .isnull() (Identical)\n",
    "print(\"\\n--- 3. Example 2: s.isnull() ---\")\n",
    "print(s.isnull())\n",
    "\n",
    "# Example 3: .notna() (The opposite)\n",
    "print(\"\\n--- 4. Example 3: s.notna() ---\")\n",
    "print(s.notna())\n",
    "\n",
    "# Example 4: Counting the missing values\n",
    "print(\"\\n--- 5. Example 4: s.isna().sum() ---\")\n",
    "print(s.isna().sum())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 1. Original Series ---\n",
    "0    10.0\n",
    "1    20.0\n",
    "2     NaN\n",
    "3    40.0\n",
    "4     NaN\n",
    "dtype: float64\n",
    "\n",
    "--- 2. Example 1: s.isna() ---\n",
    "0    False\n",
    "1    False\n",
    "2     True\n",
    "3    False\n",
    "4     True\n",
    "dtype: bool\n",
    "\n",
    "--- 3. Example 2: s.isnull() ---\n",
    "0    False\n",
    "1    False\n",
    "2     True\n",
    "3    False\n",
    "4     True\n",
    "dtype: bool\n",
    "\n",
    "--- 4. Example 3: s.notna() ---\n",
    "0     True\n",
    "1     True\n",
    "2    False\n",
    "3     True\n",
    "4    False\n",
    "dtype: bool\n",
    "\n",
    "--- 5. Example 4: s.isna().sum() ---\n",
    "2\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "`.isna()` and `.isnull()` correctly identified the two missing values (`np.nan` and `None`) as `True`. `.notna()` did the opposite. `.isna().sum()` added up the `True` values (`1 + 1`) and gave us a total count of `2`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 2\\. Intermediate Example (on a DataFrame)\n",
    "\n",
    "This is the most common use case: finding the total missing data *per column*.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'ID': [100, 101, 102, 103],\n",
    "    'Name': ['Alice', 'Bob', 'Clara', np.nan],\n",
    "    'Age': [25, 30, np.nan, 42],\n",
    "    'Email': [None, 'bob@x.com', 'clara@x.com', np.nan]\n",
    "})\n",
    "print(\"--- 6. Original DataFrame ---\")\n",
    "print(df)\n",
    "\n",
    "# Example 5: .isna() on a DataFrame\n",
    "print(\"\\n--- 7. Example 5: df.isna() (Boolean Mask) ---\")\n",
    "print(df.isna())\n",
    "\n",
    "# Example 6: .isna().sum() (The *key* command)\n",
    "# This is the summary you almost always want.\n",
    "print(\"\\n--- 8. Example 6: df.isna().sum() (Count per Column) ---\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Example 7: .notna().sum()\n",
    "print(\"\\n--- 9. Example 7: df.notna().sum() (Count per Column) ---\")\n",
    "print(df.notna().sum())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 6. Original DataFrame ---\n",
    "    ID   Name   Age        Email\n",
    "0  100  Alice  25.0         None\n",
    "1  101    Bob  30.0    bob@x.com\n",
    "2  102  Clara   NaN  clara@x.com\n",
    "3  103    NaN  42.0          NaN\n",
    "\n",
    "--- 7. Example 5: df.isna() (Boolean Mask) ---\n",
    "      ID   Name    Age  Email\n",
    "0  False  False  False   True\n",
    "1  False  False  False  False\n",
    "2  False  False   True  False\n",
    "3  False   True  False   True\n",
    "\n",
    "--- 8. Example 6: df.isna().sum() (Count per Column) ---\n",
    "ID       0\n",
    "Name     1\n",
    "Age      1\n",
    "Email    2\n",
    "dtype: int64\n",
    "\n",
    "--- 9. Example 7: df.notna().sum() (Count per Column) ---\n",
    "ID       4\n",
    "Name     3\n",
    "Age      3\n",
    "Email    2\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "The output of `df.isna().sum()` is a new Series. The *index* of this new Series is the *columns* of `df`, and the *values* are the *counts* of `NaN`s in those columns. This instantly tells us: 'Name' is missing 1 value, 'Age' is missing 1, and 'Email' is missing 2.\n",
    "\n",
    "-----\n",
    "\n",
    "### 3\\. Advanced or Tricky Case (Dates, Filtering, and Axis)\n",
    "\n",
    "**Example 8: `NaT` (Not a Time) is also `NaN`**\n",
    "`.isna()` is smart enough to find all \"missing\" types.\n",
    "\n",
    "```python\n",
    "s_time = pd.Series([\n",
    "    pd.to_datetime('2025-01-01'), \n",
    "    pd.NaT, \n",
    "    pd.to_datetime('2025-01-03')\n",
    "])\n",
    "print(\"--- 10. Series with NaT ---\")\n",
    "print(s_time)\n",
    "\n",
    "# Example 9: .isna() detects NaT\n",
    "print(\"\\n--- 11. Example 9: s_time.isna() ---\")\n",
    "print(s_time.isna())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 10. Series with NaT ---\n",
    "0   2025-01-01\n",
    "1          NaT\n",
    "2   2025-01-03\n",
    "dtype: datetime64[ns]\n",
    "\n",
    "--- 11. Example 9: s_time.isna() ---\n",
    "0    False\n",
    "1     True\n",
    "2    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "**Example 10: Summing missing values by *row***\n",
    "Use `axis=1` to find out *how many* columns are missing for each row.\n",
    "\n",
    "```python\n",
    "# Use the same df from Example 6\n",
    "print(\"\\n--- 12. Example 10: df.isna().sum(axis=1) (Count per Row) ---\")\n",
    "print(df.isna().sum(axis=1))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 12. Example 10: df.isna().sum(axis=1) (Count per Row) ---\n",
    "0    1\n",
    "1    0\n",
    "2    1\n",
    "3    2\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "**Explanation:** This tells us: Row 0 is missing 1 value (`Email`). Row 1 is complete. Row 3 is missing 2 values (`Name` and `Email`).\n",
    "\n",
    "**Example 11: Filtering for \"good\" rows with `.notna()`**\n",
    "This is a very common use.\n",
    "\n",
    "```python\n",
    "# Get all rows that have a NON-missing email\n",
    "print(\"\\n--- 13. Example 11: Filter with .notna() ---\")\n",
    "good_rows = df[df['Email'].notna()]\n",
    "print(good_rows)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 13. Example 11: Filter with .notna() ---\n",
    "    ID   Name   Age        Email\n",
    "1  101    Bob  30.0    bob@x.com\n",
    "2  102  Clara   NaN  clara@x.com\n",
    "```\n",
    "\n",
    "**Example 12: Filtering for \"bad\" rows with `.isna()`**\n",
    "\n",
    "```python\n",
    "# Get all rows that are missing an email\n",
    "print(\"\\n--- 14. Example 12: Filter with .isna() ---\")\n",
    "bad_rows = df[df['Email'].isna()]\n",
    "print(bad_rows)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 14. Example 12: Filter with .isna() ---\n",
    "    ID   Name   Age Email\n",
    "0  100  Alice  25.0  None\n",
    "3  103    NaN  42.0   NaN\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### 4\\. Real-World Use Case\n",
    "\n",
    "**Example 13: The `df.info()` vs. `df.isna().sum()` Workflow**\n",
    "This is the standard \"data check\" workflow.\n",
    "\n",
    "```python\n",
    "# 1. df.info() gives you \"non-null\" counts\n",
    "print(\"--- 15. Example 13: The df.info() view ---\")\n",
    "df.info()\n",
    "\n",
    "# 2. df.isna().sum() gives you \"null\" counts\n",
    "print(\"\\n--- 16. The df.isna().sum() view (more direct) ---\")\n",
    "print(df.isna().sum())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 15. Example 13: The df.info() view ---\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 4 entries, 0 to 3\n",
    "Data columns (total 4 columns):\n",
    " #   Column  Non-Null Count  Dtype  \n",
    "---  ------  --------------  -----  \n",
    " 0   ID      4 non-null      int64  \n",
    " 1   Name    3 non-null      object \n",
    " 2   Age     3 non-null      float64\n",
    " 3   Email   2 non-null      object \n",
    "dtypes: float64(1), int64(1), object(2)\n",
    "memory usage: 256.0+ bytes\n",
    "\n",
    "--- 16. The df.isna().sum() view (more direct) ---\n",
    "ID       0\n",
    "Name     1\n",
    "Age      1\n",
    "Email    2\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "**Explanation:** `info()` shows 4 total entries, and 'Email' has 2 \"non-nulls\" (so you have to do the math: 4 - 2 = 2 missing). `isna().sum()` *directly* tells you: 'Email' has 2 missing. It's often clearer.\n",
    "\n",
    "**Example 14: Finding columns *with any* missing data**\n",
    "\n",
    "```python\n",
    "print(\"\\n--- 17. Example 14: Programmatic list of bad columns ---\")\n",
    "missing_counts = df.isna().sum()\n",
    "cols_with_missing = missing_counts[missing_counts > 0]\n",
    "print(cols_with_missing)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 17. Example 14: Programmatic list of bad columns ---\n",
    "Name     1\n",
    "Age      1\n",
    "Email    2\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "**Explanation:** This is a powerful programming pattern. We get the counts, then use a boolean filter *on the counts* to find only the columns that have 1 or more missing values.\n",
    "\n",
    "-----\n",
    "\n",
    "### 5\\. Common Mistakes / Pitfalls\n",
    "\n",
    "**Mistake 15: `np.nan == np.nan` (The Classic)**\n",
    "You *cannot* use `==` to find `NaN`.\n",
    "\n",
    "```python\n",
    "print(\"\\n--- 18. Mistake 15: The np.nan == np.nan pitfall ---\")\n",
    "print(f\"np.nan == np.nan is: {np.nan == np.nan}\")\n",
    "\n",
    "# Wrong code\n",
    "s = pd.Series([1, np.nan])\n",
    "print(\"\\n--- 19. Trying to filter with == np.nan (FAILS) ---\")\n",
    "print(s[s == np.nan])\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "\n",
    "```\n",
    "--- 18. Mistake 15: The np.nan == np.nan pitfall ---\n",
    "np.nan == np.nan is: False\n",
    "\n",
    "--- 19. Trying to filter with == np.nan (FAILS) ---\n",
    "Series([], dtype: float64)\n",
    "```\n",
    "\n",
    "**Why it happens:** By definition in computing, `NaN` (Not a Number) is *never* equal to anything, not even itself.\n",
    "**Correction:** You *must* use `s.isna()`: `s[s.isna()]`.\n",
    "\n",
    "**Mistake 16: Forgetting `.sum()`**\n",
    "\n",
    "```python\n",
    "# Wrong code\n",
    "print(\"\\n--- 20. Mistake 16: Forgetting .sum() ---\")\n",
    "print(df.isna())\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "(This prints a giant boolean DataFrame, not the counts you wanted.)\n",
    "**Why it happens:** This is a common beginner mistake. You get the boolean \"mask\" but forget to \"count\" the `True` values with `.sum()`.\n",
    "\n",
    "**Mistake 17: `.isna().count()` vs. `.isna().sum()`**\n",
    "\n",
    "```python\n",
    "s = pd.Series([1, 2, np.nan])\n",
    "print(\"\\n--- 21. Mistake 17: .count() is not .sum() ---\")\n",
    "print(f\".isna().sum(): {s.isna().sum()}\")   # Correct (1)\n",
    "print(f\".isna().count(): {s.isna().count()}\") # Wrong (3)\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "\n",
    "```\n",
    "--- 21. Mistake 17: .count() is not .sum() ---\n",
    ".isna().sum(): 1\n",
    ".isna().count(): 3\n",
    "```\n",
    "\n",
    "**Why it happens:** `.count()` counts *all* entries in the Series. `.sum()` adds up the `True` values. You want `.sum()`.\n",
    "\n",
    "**Mistake 18: `df.sum()` vs. `df.isna().sum()`**\n",
    "\n",
    "```python\n",
    "df_nums = pd.DataFrame({'A': [1, 10, np.nan]})\n",
    "print(\"\\n--- 22. Mistake 18: Confusing .sum() ---\")\n",
    "print(f\"df.sum(): \\n{df_nums.sum()}\")\n",
    "print(f\"\\ndf.isna().sum(): \\n{df_nums.isna().sum()}\")\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "\n",
    "```\n",
    "--- 22. Mistake 18: Confusing .sum() ---\n",
    "df.sum(): \n",
    "A    11.0\n",
    "dtype: float64\n",
    "\n",
    "df.isna().sum(): \n",
    "A    1\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "**Why it happens:** `df.sum()` adds the *data*. `df.isna().sum()` adds the *missing value flags*. They are totally different.\n",
    "\n",
    "\n",
    "\n",
    "#  second subtopic: Detecting Missing Data Patterns.\n",
    "\n",
    "-----\n",
    "\n",
    "This topic is about moving from *counting* missing values to *finding the specific rows* that contain them. The two tools for this are `.any()` and `.all()`.\n",
    "\n",
    "  * **`.any()`** asks the question: \"Is there *at least one* `True` value here?\"\n",
    "      * `df.isna().any(axis=1)`: \"Show me any **row** that has *at least one* missing value.\"\n",
    "  * **`.all()`** asks the question: \"Are *all* the values `True` here?\"\n",
    "      * `df.isna().all(axis=1)`: \"Show me any **row** that is *completely empty* (all values are `NaN`).\"\n",
    "\n",
    "This is how you find the \"problem rows\" that you need to either drop or fix.\n",
    "\n",
    "**How It Works in Memory**: First, `df.isna()` creates the `True`/`False` boolean mask, which is fast. Then, `.any(axis=1)` or `.all(axis=1)` performs a \"reduction\" *across* the rows (horizontally). It looks at all the `True`/`False` values in a single row and \"reduces\" them to a single `True` or `False` answer. This is a highly optimized C-level operation, so it's very fast. The result is a new, small `pd.Series` of booleans (one for each row) which you can then use as a filter.\n",
    "\n",
    "**When to Use This**:\n",
    "\n",
    "  * [cite\\_start]Use `df[df.isna().any(axis=1)]` to get a \"to-do list\" of all rows that need cleaning[cite: 45].\n",
    "  * Use `df[df.notna().all(axis=1)]` to find all \"perfectly clean\" rows that have *no* missing data.\n",
    "  * Use `df[df.isna().all(axis=1)]` to find and delete *completely blank* rows, which are sometimes in data files.\n",
    "  * Use `df.isna().any(axis=0)` (or just `df.isna().any()`) to find out *which columns* contain *any* `NaN`s.\n",
    "\n",
    "-----\n",
    "\n",
    "### 0\\. Syntax & Parameters (MUST COME FIRST)\n",
    "\n",
    "You call `.any()` or `.all()` on a boolean DataFrame (like the one `df.isna()` returns).\n",
    "\n",
    "```python\n",
    "dataframe_mask.any(axis=0, ...)\n",
    "dataframe_mask.all(axis=0, ...)\n",
    "```\n",
    "\n",
    "  * **`axis`**\n",
    "      * **What it does:** This is the most important parameter. It tells Pandas which *direction* to \"collapse\" or \"reduce\" the data.\n",
    "      * **Default value:** `0` (or `'index'`)\n",
    "      * **When you would use it:**\n",
    "          * `axis=0` (default): Collapses \"down\" the rows. It asks, \"Does this **column** have any `True`s?\" This will return one answer *per column*.\n",
    "          * `axis=1` (or `'columns'`): Collapses \"across\" the columns. It asks, \"Does this **row** have any `True`s?\" This will return one answer *per row*.\n",
    "      * **Mnemonic:** `axis=1` works on rows. I remember this as \"axis 1 goes on the fritz, scanning rows is its biz.\" Or, `axis=1` moves horizontally.\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. Basic Example\n",
    "\n",
    "Let's see the two axes in action.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ID': [100, 101, 102, 103],\n",
    "    'Name': ['Alice', 'Bob', 'Clara', np.nan],\n",
    "    'Age': [25, 30, np.nan, 42],\n",
    "    'Email': [None, 'bob@x.com', 'clara@x.com', np.nan]\n",
    "})\n",
    "print(\"--- 1. Original DataFrame ---\")\n",
    "print(df)\n",
    "\n",
    "# Example 1: Create the boolean mask\n",
    "mask_df = df.isna()\n",
    "print(\"\\n--- 2. Example 1: The .isna() mask ---\")\n",
    "print(mask_df)\n",
    "\n",
    "# Example 2: .any(axis=0) (the default)\n",
    "# \"Does this COLUMN have any True (missing) values?\"\n",
    "print(\"\\n--- 3. Example 2: mask_df.any(axis=0) (per COLUMN) ---\")\n",
    "print(mask_df.any(axis=0))\n",
    "\n",
    "# Example 3: .any(axis=1)\n",
    "# \"Does this ROW have any True (missing) values?\"\n",
    "print(\"\\n--- 4. Example 3: mask_df.any(axis=1) (per ROW) ---\")\n",
    "print(mask_df.any(axis=1))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 1. Original DataFrame ---\n",
    "    ID   Name   Age        Email\n",
    "0  100  Alice  25.0         None\n",
    "1  101    Bob  30.0    bob@x.com\n",
    "2  102  Clara   NaN  clara@x.com\n",
    "3  103    NaN  42.0          NaN\n",
    "\n",
    "--- 2. Example 1: The .isna() mask ---\n",
    "      ID   Name    Age  Email\n",
    "0  False  False  False   True\n",
    "1  False  False  False  False\n",
    "2  False  False   True  False\n",
    "3  False   True  False   True\n",
    "\n",
    "--- 3. Example 2: mask_df.any(axis=0) (per COLUMN) ---\n",
    "ID       False\n",
    "Name      True\n",
    "Age       True\n",
    "Email     True\n",
    "dtype: bool\n",
    "\n",
    "--- 4. Example 3: mask_df.any(axis=1) (per ROW) ---\n",
    "0     True\n",
    "1    False\n",
    "2     True\n",
    "3     True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "  * `axis=0` (per column): 'ID' had *no* `True`s, so it's `False`. 'Name', 'Age', and 'Email' all had *at least one* `True`, so they are `True`.\n",
    "  * `axis=1` (per row): Row 0 had a `True` (in 'Email'), so it's `True`. Row 1 was all `False`, so it's `False`. Rows 2 and 3 both had `True`s, so they are `True`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 2\\. Intermediate Example (Using as a Filter)\n",
    "\n",
    "Now we can use the `True`/`False` Series from `axis=1` as a filter to *select* the problem rows.\n",
    "\n",
    "```python\n",
    "# Use the same mask_df from the previous example\n",
    "mask_df = df.isna()\n",
    "print(\"--- 5. Original DataFrame ---\")\n",
    "print(df)\n",
    "\n",
    "# Example 4: Get the mask for \"problem rows\"\n",
    "problem_rows_mask = mask_df.any(axis=1)\n",
    "print(\"\\n--- 6. Example 4: Mask for rows with ANY NaN ---\")\n",
    "print(problem_rows_mask)\n",
    "\n",
    "# Example 5: Use the mask to filter the DataFrame\n",
    "# [cite_start]This is the key pattern from the roadmap [cite: 45]\n",
    "problem_rows = df[problem_rows_mask]\n",
    "print(\"\\n--- 7. Example 5: df[df.isna().any(axis=1)] ---\")\n",
    "print(problem_rows)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 5. Original DataFrame ---\n",
    "    ID   Name   Age        Email\n",
    "0  100  Alice  25.0         None\n",
    "1  101    Bob  30.0    bob@x.com\n",
    "2  102  Clara   NaN  clara@x.com\n",
    "3  103    NaN  42.0          NaN\n",
    "\n",
    "--- 6. Example 4: Mask for rows with ANY NaN ---\n",
    "0     True\n",
    "1    False\n",
    "2     True\n",
    "3     True\n",
    "dtype: bool\n",
    "\n",
    "--- 7. Example 5: df[df.isna().any(axis=1)] ---\n",
    "    ID   Name   Age        Email\n",
    "0  100  Alice  25.0         None\n",
    "2  102  Clara   NaN  clara@x.com\n",
    "3  103    NaN  42.0          NaN\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "This is the core concept. We generated the `problem_rows_mask` (`[True, False, True, True]`) and then used it as a filter on the original `df`. The result is a new DataFrame `problem_rows` containing *only* the rows (0, 2, and 3) that had at least one `NaN`.\n",
    "\n",
    "**Example 6: Filtering for \"perfect rows\"**\n",
    "We can do the opposite by using `.notna()` and `.all()`.\n",
    "\n",
    "```python\n",
    "# \"Find rows where ALL values are NOTNA\"\n",
    "perfect_rows_mask = df.notna().all(axis=1)\n",
    "print(\"\\n--- 8. Example 6: Mask for 'perfect' rows ---\")\n",
    "print(perfect_rows_mask)\n",
    "\n",
    "print(\"\\n--- 9. 'Perfect' rows ---\")\n",
    "print(df[perfect_rows_mask])\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 8. Example 6: Mask for 'perfect' rows ---\n",
    "0    False\n",
    "1     True\n",
    "2    False\n",
    "3    False\n",
    "dtype: bool\n",
    "\n",
    "--- 9. 'Perfect' rows ---\n",
    "    ID Name   Age      Email\n",
    "1  101  Bob  30.0  bob@x.com\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "`df.notna()` creates the opposite mask. `all(axis=1)` then checks which rows are `True` in *all* columns. Only Row 1 (Bob) was \"perfectly\" complete.\n",
    "\n",
    "-----\n",
    "\n",
    "### 3\\. Advanced or Tricky Case (Using `.all()`)\n",
    "\n",
    "`.all()` is less common, but useful for finding *completely* blank rows.\n",
    "\n",
    "```python\n",
    "# Add a completely blank row\n",
    "df.loc[4] = [np.nan, np.nan, np.nan, np.nan]\n",
    "print(\"--- 10. DataFrame with blank row ---\")\n",
    "print(df)\n",
    "\n",
    "# Example 7: Find rows that are ALL NaN\n",
    "all_nan_mask = df.isna().all(axis=1)\n",
    "print(\"\\n--- 11. Example 7: Mask for ALL NaN rows ---\")\n",
    "print(all_nan_mask)\n",
    "\n",
    "print(\"\\n--- 12. Blank rows ---\")\n",
    "print(df[all_nan_mask])\n",
    "\n",
    "# Example 8: Find rows that are missing BOTH Name AND Email\n",
    "cols_of_interest = ['Name', 'Email']\n",
    "mask_both_missing = df[cols_of_interest].isna().all(axis=1)\n",
    "print(\"\\n--- 13. Example 8: Mask for missing Name AND Email ---\")\n",
    "print(mask_both_missing)\n",
    "\n",
    "print(\"\\n--- 14. Rows missing both ---\")\n",
    "print(df[mask_both_missing])\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 10. DataFrame with blank row ---\n",
    "      ID   Name   Age        Email\n",
    "0  100.0  Alice  25.0         None\n",
    "1  101.0    Bob  30.0    bob@x.com\n",
    "2  102.0  Clara   NaN  clara@x.com\n",
    "3  103.0    NaN  42.0          NaN\n",
    "4    NaN    NaN   NaN          NaN\n",
    "\n",
    "--- 11. Example 7: Mask for ALL NaN rows ---\n",
    "0    False\n",
    "1    False\n",
    "2    False\n",
    "3    False\n",
    "4     True\n",
    "dtype: bool\n",
    "\n",
    "--- 12. Blank rows ---\n",
    "    ID Name  Age Email\n",
    "4 NaN  NaN  NaN   NaN\n",
    "\n",
    "--- 13. Example 8: Mask for missing Name AND Email ---\n",
    "0    False\n",
    "1    False\n",
    "2    False\n",
    "3     True\n",
    "4     True\n",
    "dtype: bool\n",
    "\n",
    "--- 14. Rows missing both ---\n",
    "      ID Name   Age Email\n",
    "3  103.0  NaN  42.0   NaN\n",
    "4    NaN  NaN   NaN   NaN\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "  * **Example 7:** `df.isna().all(axis=1)` only returned `True` for row 4, which was `NaN` in every single column.\n",
    "  * **Example 8:** This is an advanced trick. We first *sliced* the DataFrame (`df[cols_of_interest]`) and *then* ran our `isna().all(axis=1)` check. This let us find rows (3 and 4) that were missing *all* of the specific columns we cared about.\n",
    "\n",
    "-----\n",
    "\n",
    "### 4\\. Real-World Use Case\n",
    "\n",
    "**Example 9: Dropping all \"problem\" rows**\n",
    "You have a dataset and you decide that any row with *any* missing data is unusable and must be dropped.\n",
    "\n",
    "```python\n",
    "print(\"--- 15. Example 9: Original DataFrame ---\")\n",
    "print(df) # This is our 5-row df\n",
    "\n",
    "# 1. Get the mask for \"problem\" rows\n",
    "mask = df.isna().any(axis=1)\n",
    "\n",
    "# 2. Get the *indexes* of those rows\n",
    "rows_to_drop = df[mask].index\n",
    "print(\"\\n--- 16. Indexes to drop ---\")\n",
    "print(rows_to_drop)\n",
    "\n",
    "# 3. Drop them\n",
    "df_clean = df.drop(rows_to_drop)\n",
    "print(\"\\n--- 17. Cleaned DataFrame ---\")\n",
    "print(df_clean)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 15. Example 9: Original DataFrame ---\n",
    "      ID   Name   Age        Email\n",
    "0  100.0  Alice  25.0         None\n",
    "1  101.0    Bob  30.0    bob@x.com\n",
    "2  102.0  Clara   NaN  clara@x.com\n",
    "3  103.0    NaN  42.0          NaN\n",
    "4    NaN    NaN   NaN          NaN\n",
    "\n",
    "--- 16. Indexes to drop ---\n",
    "Index([0, 2, 3, 4], dtype='int64')\n",
    "\n",
    "--- 17. Cleaned DataFrame ---\n",
    "      ID Name   Age      Email\n",
    "1  101.0  Bob  30.0  bob@x.com\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "This workflow found all rows (0, 2, 3, 4) with at least one `NaN`, got their index labels, and then used `df.drop()` to remove them, leaving only the one \"perfect\" row. (Note: `df.dropna()` is the shortcut for this exact operation, which will be in the next topic).\n",
    "\n",
    "**Example 10: Dropping only *completely blank* rows**\n",
    "This is a safer cleaning step. You don't want to drop `row 0` (Alice, missing email), but you *do* want to drop `row 4` (all `NaN`).\n",
    "\n",
    "```python\n",
    "# 1. Get the mask for *all* NaN rows\n",
    "mask = df.isna().all(axis=1)\n",
    "\n",
    "# 2. Get the indexes\n",
    "rows_to_drop = df[mask].index\n",
    "print(\"\\n--- 18. Example 10: Blank row indexes ---\")\n",
    "print(rows_to_drop)\n",
    "\n",
    "# 3. Drop them\n",
    "df_safer_clean = df.drop(rows_to_drop)\n",
    "print(\"\\n--- 19. Safer Clean (only blank row dropped) ---\")\n",
    "print(df_safer_clean)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 18. Example 10: Blank row indexes ---\n",
    "Index([4], dtype='int64')\n",
    "\n",
    "--- 19. Safer Clean (only blank row dropped) ---\n",
    "      ID   Name   Age        Email\n",
    "0  100.0  Alice  25.0         None\n",
    "1  101.0    Bob  30.0    bob@x.com\n",
    "2  102.0  Clara   NaN  clara@x.com\n",
    "3  103.0    NaN  42.0          NaN\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "This time, the mask only identified `row 4`. The resulting `df_safer_clean` still has the partially-null rows, but the *completely useless* blank row is gone.\n",
    "\n",
    "-----\n",
    "\n",
    "### 5\\. Common Mistakes / Pitfalls\n",
    "\n",
    "**Mistake 11: Confusing `axis=0` and `axis=1`**\n",
    "This is the \\#1 mistake. You want to find *problem rows* but you use the *default axis*.\n",
    "\n",
    "```python\n",
    "# Wrong code\n",
    "df = pd.DataFrame({'A': [1, np.nan], 'B': [3, 4]})\n",
    "print(\"\\n--- 20. Example 11: Original ---\")\n",
    "print(df)\n",
    "\n",
    "# You want to find the problem ROW (row 1)\n",
    "# But you use the default axis=0\n",
    "mask_wrong = df.isna().any() # axis=0 is default\n",
    "print(\"\\n--- 21. Wrong: .any(axis=0) ---\")\n",
    "print(mask_wrong)\n",
    "\n",
    "print(\"\\n--- 22. Filter (FAILS) ---\")\n",
    "try:\n",
    "    df[mask_wrong]\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "\n",
    "```\n",
    "--- 20. Example 11: Original ---\n",
    "     A  B\n",
    "0  1.0  3\n",
    "1  NaN  4\n",
    "\n",
    "--- 21. Wrong: .any(axis=0) ---\n",
    "A     True\n",
    "B    False\n",
    "dtype: bool\n",
    "\n",
    "--- 22. Filter (FAILS) ---\n",
    "\"['A', 'B'] not in index\"\n",
    "```\n",
    "\n",
    "**Why it happens:** `df.isna().any(axis=0)` returned a boolean Series *for the columns* (`A` is `True`, `B` is `False`). When you used this as a filter `df[mask_wrong]`, Pandas tried to find *columns* named `True` and `False`, which failed.\n",
    "**Correction:** You *must* use `axis=1` to get a mask for the *rows*: `df[df.isna().any(axis=1)]`.\n",
    "\n",
    "**Mistake 12: Using `.any()` to get \"perfect rows\"**\n",
    "This is a logic mistake.\n",
    "\n",
    "```python\n",
    "# Wrong code\n",
    "df = pd.DataFrame({'A': [1, np.nan], 'B': [3, 4]})\n",
    "print(\"\\n--- 23. Example 12: Logic mistake ---\")\n",
    "# You want row 0, but this...\n",
    "mask = df.notna().any(axis=1) # \"Has at least one good value\"\n",
    "print(df[mask])\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "\n",
    "```\n",
    "--- 23. Example 12: Logic mistake ---\n",
    "     A  B\n",
    "0  1.0  3\n",
    "1  NaN  4\n",
    "```\n",
    "\n",
    "**Why it happens:** You asked \"Show me rows with *any* good value.\" Row 1 has a `NaN`... but it *also* has a `4`, which is a good value. So `any()` returns `True`.\n",
    "**Correction:** To find \"perfect rows\", you must use `.all()`: `df[df.notna().all(axis=1)]`.\n",
    "\n",
    "**Mistake 13: Using `df.any()` instead of `df.isna().any()`**\n",
    "\n",
    "```python\n",
    "# Wrong code\n",
    "df = pd.DataFrame({'A': [1, 0], 'B': [0, 0]})\n",
    "print(\"\\n--- 24. Example 13: .any() on numbers ---\")\n",
    "print(df.any(axis=1))\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "\n",
    "```\n",
    "--- 24. Example 13: .any() on numbers ---\n",
    "0    True\n",
    "1    False\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "**Why it happens:** `.any()` on a numeric DataFrame checks for `0` (False) vs. non-zero (True). This has *nothing* to do with `NaN`s.\n",
    "**Correction:** Always start with `.isna()` or `.notna()` to create the boolean mask *first*.\n",
    "\n",
    "**Mistake 14: Confusing `.sum()` and `.any()`**\n",
    "\n",
    "```python\n",
    "# Both can be used for filtering, but one is clearer\n",
    "df = pd.DataFrame({'A': [1, np.nan], 'B': [3, 4]})\n",
    "\n",
    "# Using .sum()\n",
    "mask_sum = df.isna().sum(axis=1) > 0\n",
    "print(\"\\n--- 25. Example 14: Filtering with .sum() ---\")\n",
    "print(df[mask_sum])\n",
    "\n",
    "# Using .any()\n",
    "mask_any = df.isna().any(axis=1)\n",
    "print(\"\\n--- 26. Filtering with .any() ---\")\n",
    "print(df[mask_any])\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- 25. Example 14: Filtering with .sum() ---\n",
    "     A  B\n",
    "1  NaN  4\n",
    "\n",
    "--- 26. Filtering with .any() ---\n",
    "     A  B\n",
    "1  NaN  4\n",
    "```\n",
    "\n",
    "**Why it happens:** Both work. `sum() > 0` (is the sum of `True`s greater than 0?) is logically identical to `.any()` (is there *any* `True`?). However, `.any()` is more direct, more readable, and slightly faster as it can \"short-circuit\" (stop checking a row as soon as it finds one `True`), whereas `.sum()` has to count them all.\n",
    "\n",
    "**Mistake 15: Not subsetting columns for `.all()`**\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, np.nan], \n",
    "    'B': [np.nan, 4], \n",
    "    'C': [5, 6]\n",
    "})\n",
    "print(\"\\n--- 27. Example 15: .all() on whole DF ---\")\n",
    "# You're looking for rows missing both A and B\n",
    "# But you do this...\n",
    "mask = df.isna().all(axis=1)\n",
    "print(df[mask])\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "\n",
    "```\n",
    "--- 27. Example 15: .all() on whole DF ---\n",
    "Empty DataFrame\n",
    "Columns: [A, B, C]\n",
    "Index: []\n",
    "```\n",
    "\n",
    "**Why it happens:** You asked, \"Show me rows where *all* columns (A, B, *and C*) are `NaN`.\" No row matched that.\n",
    "**Correction:** You must *subset* the columns first: `df[df[['A', 'B']].isna().all(axis=1)]`.\n",
    "\n",
    "----\n",
    "\n",
    "Here are the combined remaining sections for all **Detection Methods** (`.isna()`, `.notna()`, `.isnull()`, `.sum()`, `.any()`, `.all()`).\n",
    "\n",
    "-----\n",
    "\n",
    "### 6\\. Key Terms (Explained Simply)\n",
    "\n",
    "  * **`NaN` (Not a Number):** The standard marker for missing *numeric* data.\n",
    "  * **`None`:** The Python object for \"nothing.\" It's also treated as a missing value in Pandas.\n",
    "  * **`NaT` (Not a Time):** The \"missing value\" marker for `datetime64[ns]` columns. `.isna()` finds this too.\n",
    "  * **Boolean Mask:** A DataFrame or Series of the *same shape* as the original, but filled with only `True` and `False` values. `df.isna()` returns one.\n",
    "  * **`.isna()` / `.isnull()`:** Identical methods. They create a boolean mask, returning `True` for any missing value (`NaN`, `None`, `NaT`).\n",
    "  * **`.notna()`:** The opposite. It returns `True` for any cell that *has a value*.\n",
    "  * **`.sum()`:** When chained (e.g., `df.isna().sum()`), it treats `True` as `1` and `False` as `0`, effectively *counting* the missing values.\n",
    "  * **`.any()`:** A method that \"collapses\" a boolean mask. It checks if *any* `True` value exists along an axis.\n",
    "  * **`.all()`:** A method that \"collapses\" a boolean mask. It checks if *all* values are `True` along an axis.\n",
    "  * **`axis=0`**: The \"down\" axis. When used in `.sum()`, `.any()`, or `.all()`, it produces one result *per column*.\n",
    "  * **`axis=1`**: The \"across\" axis. When used in `.sum()`, `.any()`, or `.all()`, it produces one result *per row*.\n",
    "\n",
    "-----\n",
    "\n",
    "### 7\\. Best Practices\n",
    "\n",
    "  * **Always Check:** Run `df.info()` and `df.isna().sum()` *every time* you load a new dataset. This is the first step of data cleaning.\n",
    "  * **Prefer `.isna()`:** Use `.isna()` and `.notna()`. They are the modern, clear standard. `.isnull()` is just an alias.\n",
    "  * **Use `.sum()` for Counts:** The standard \"missing value report\" is `df.isna().sum()`. This gives you a fast count of `NaN`s *per column*.\n",
    "  * **Use `.any(axis=1)` to Find Rows:** The standard way to find *all rows* that have *any* missing data is `df[df.isna().any(axis=1)]`.\n",
    "  * **Use `.all(axis=1)` to Find Blank Rows:** The standard way to find *completely blank* rows is `df[df.isna().all(axis=1)]`.\n",
    "  * **Never Use `== np.nan`:** You cannot find `NaN`s with `df == np.nan`. This will always return `False`. You *must* use `df.isna()`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 8\\. Mini Summary\n",
    "\n",
    "  * Missing values are `NaN`, `None`, or `NaT`.\n",
    "  * **`.isna()`** (or `.isnull()`) returns a `True`/`False` mask where `True` means \"missing.\"\n",
    "  * **`.notna()`** is the opposite, where `True` means \"has a value.\"\n",
    "  * **`df.isna().sum()`** (with default `axis=0`) is the most important command. It gives you a **count of missing values in every column**.\n",
    "  * **`df.isna().any(axis=1)`** creates a mask to find **rows with *at least one* `NaN`**.\n",
    "  * **`df.isna().all(axis=1)`** creates a mask to find **rows that are *completely* `NaN`**.\n",
    "\n",
    "-----\n",
    "\n",
    "### 10\\. Practice Tasks\n",
    "\n",
    "**Data for Tasks:**\n",
    "\n",
    "```python\n",
    "df_practice = pd.DataFrame({\n",
    "    'name': ['Frodo', 'Sam', 'Pippin', 'Merry', np.nan],\n",
    "    'age': [50, 33, np.nan, 36, 35],\n",
    "    'email': ['f@shire.com', 's@shire.com', 'p@shire.com', np.nan, np.nan]\n",
    "})\n",
    "```\n",
    "\n",
    "**Task 22 (Easy):**\n",
    "Run the single command that will show you the *total count* of missing values for *each column* in `df_practice`.\n",
    "\n",
    "**Task 23 (Medium):**\n",
    "Find all rows in `df_practice` that are **missing an 'email'** address.\n",
    "\n",
    "**Task 24 (Hard):**\n",
    "Find all rows in `df_practice` that have **at least one missing value** (in *any* column).\n",
    "\n",
    "**Bonus Task 25 (Hardest):**\n",
    "Find all rows in `df_practice` that are \"fully complete\" (have **zero missing values**).\n",
    "\n",
    "-----\n",
    "\n",
    "### 11\\. Recommended Next Topic\n",
    "\n",
    "You have now mastered *detecting* missing data. The next logical step from the roadmap is to learn the specific methods for *handling* and *fixing* them.\n",
    "\n",
    "[cite\\_start]**Recommended:** **Handling strategies (`.dropna()`, `.fillna()`, `.interpolate()`)** [cite: 46-48]\n",
    "\n",
    "-----\n",
    "\n",
    "### 12\\. Quick Reference Card\n",
    "\n",
    "| Method | What It Does | Example |\n",
    "| :--- | :--- | :--- |\n",
    "| **`.isna()`** | (Alias `.isnull()`) Returns `True`/`False` mask. `True` = missing. | `df.isna()` |\n",
    "| **`.notna()`** | Returns `True`/`False` mask. `True` = has value. | `df.notna()` |\n",
    "| **`.isna().sum()`** | **(Most common)** Counts `NaN`s *per column*. | `df.isna().sum()` |\n",
    "| **`.isna().sum(axis=1)`**| Counts `NaN`s *per row*. | `df.isna().sum(axis=1)` |\n",
    "| **`.any(axis=1)`** | (On `isna()` mask) Returns `True` for rows with *any* `NaN`. | `df.isna().any(axis=1)` |\n",
    "| **`.all(axis=1)`** | (On `isna()` mask) Returns `True` for rows that are *all* `NaN`. | `df.isna().all(axis=1)` |\n",
    "| **`.any()` (default)** | (On `isna()` mask) Returns `True` for *columns* with *any* `NaN`. | `df.isna().any()` |\n",
    "\n",
    "-----\n",
    "\n",
    "### 13\\. Common Interview Questions\n",
    "\n",
    "1.  **What's the first thing you do when you get a new DataFrame?**\n",
    "      * I run `df.info()` and `df.isna().sum()`. `info()` tells me the `dtypes` and non-null counts, and `isna().sum()` gives me a direct, scannable list of missing value counts per column.\n",
    "2.  **How do you find all rows that have *any* missing data?**\n",
    "      * I use a boolean filter with `.any()` on `axis=1`: `df[df.isna().any(axis=1)]`.\n",
    "3.  **How do you find all rows that are *perfectly* complete, with no missing data?**\n",
    "      * I use `.notna()` with `.all()` on `axis=1`: `df[df.notna().all(axis=1)]`.\n",
    "4.  **What's the difference between `df.isna().sum()` and `df.isna().count()`?**\n",
    "      * `.sum()` adds the `True` values (which are `1`s) to *count the `NaN`s*. This is what you want.\n",
    "      * `.count()` simply counts *all* the boolean values in the mask (the total number of rows), which is not useful.\n",
    "5.  **Why doesn't `df[df['col'] == np.nan]` work?**\n",
    "      * `np.nan` is a special float, and by definition, it is *never* equal to anything, including itself. You *must* use the `df['col'].isna()` method.\n",
    "\n",
    "-----\n",
    "\n",
    "### 14\\. Performance Considerations\n",
    "\n",
    "  * **Time Complexity:** All these methods (`.isna()`, `.notna()`, `.sum()`, `.any()`, `.all()`) are highly optimized C-level operations. They are **O(n\\*m)**, where 'n' is rows and 'm' is columns. For a Series, they are **O(n)**.\n",
    "  * **Vectorization:** These are all fully vectorized. They are *the* fastest way to detect `NaN`s. A Python `for` loop to check for `NaN`s would be thousands of times slower.\n",
    "  * **Memory Usage:** `df.isna()` creates a *new DataFrame* of booleans, which is the same size as the original but very memory-light (booleans are 1 byte each). The chained methods (`.sum()`, `.any()`, etc.) create a *new, very small Series* as their output. The memory impact is minimal.\n",
    "  * **Short-Circuiting:** `.any()` and `.all()` are \"short-circuiting.\" When checking a row, `.any()` will stop and return `True` on the *first* `True` it finds. `.all()` will stop and return `False` on the *first* `False` it finds. This makes them slightly faster than `.sum()`, which has to check every value.\n",
    "\n",
    "-----\n",
    "\n",
    "### 15\\. When NOT to Use This\n",
    "\n",
    "  * **Don't use `== np.nan`:** (As mentioned). It will fail.\n",
    "  * **Don't use `.any()` or `.all()` on a non-boolean DataFrame:** `df.any()` will check if values are non-zero, not if they are `NaN`. Always start with `.isna()` or `.notna()` first.\n",
    "  * **Don't confuse the axes:** `df.isna().sum(axis=1)` (count *per row*) is very different from `df.isna().sum()` (count *per column*). Be sure you know which one you're asking for.\n",
    "  * **Don't use `.count()` to find `NaN`s:** `df.count()` counts *non-missing* values. `df.isna().sum()` counts *missing* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e65cdd-3e0a-41d1-89dc-85f1c70c1dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
