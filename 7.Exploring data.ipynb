{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d01ed5a-6bd6-4eaf-8638-8377d930b033",
   "metadata": {},
   "source": [
    "# 7.Exploring data\n",
    "\n",
    "-----\n",
    "\n",
    "This group of attributes and methods are your \"first-look\" tools. When you first load a dataset (e.g., from a CSV), you can't just look at all 2 million rows. These are your \"doctor's checkup\" tools—they let you take a quick \"pulse\" of the data to understand its **shape**, **size**, **data types**, and **content** *without* changing anything.\n",
    "\n",
    "**How It Works in Memory**: These are (mostly) very fast and cheap. `.shape`, `.columns`, `.index`, and `.dtypes` are just **attributes**; they are properties stored *with* the DataFrame, so looking them up is instant (O(1) time). `.head()` and `.tail()` are also fast, as they just grab the first or last few rows. `.info()` and `.describe()` are the only ones that have to *do work*—they scan your data to count non-null values or calculate statistics, which can take a moment on very large datasets.\n",
    "\n",
    "**When to Use This**: You should use these **every single time** you load a new dataset. This is *always* Step 1.\n",
    "\n",
    "  * Use `.head()` to see what your data looks like.\n",
    "  * Use `.info()` to check for missing (`NaN`) values and wrong data types.\n",
    "  * Use `.shape` to see how big your dataset is.\n",
    "  * Use `.describe()` to check for \"weird\" data (like an `Age` of -5 or 500).\n",
    "\n",
    "-----\n",
    "\n",
    "### 0\\. Syntax & Parameters (MUST COME FIRST)\n",
    "\n",
    "These are a mix of **attributes (no `()`)** and **methods (with `()`)**.\n",
    "\n",
    "#### Attributes (No Parentheses)\n",
    "\n",
    "```python\n",
    "# Returns a tuple (rows, columns)\n",
    "dataframe.shape\n",
    "\n",
    "# Returns the Index object for the rows\n",
    "dataframe.index\n",
    "\n",
    "# Returns the Index object for the columns\n",
    "dataframe.columns\n",
    "\n",
    "# Returns a Series listing the data type of each column\n",
    "dataframe.dtypes\n",
    "```\n",
    "\n",
    "#### Methods (With Parentheses)\n",
    "\n",
    "```python\n",
    "# Returns the first n rows\n",
    "dataframe.head(n=5)\n",
    "```\n",
    "\n",
    "  * **`n`**: The number of rows to return.\n",
    "      * **Default:** `5`\n",
    "      * **When to use:** Use `df.head(10)` to see more rows, or `df.head(2)` to see fewer.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "# Returns the last n rows\n",
    "dataframe.tail(n=5)\n",
    "```\n",
    "\n",
    "  * **`n`**: The number of rows to return.\n",
    "      * **Default:** `5`\n",
    "      * **When to use:** Same as `.head()`. Useful for checking if data is sorted by date.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "# Prints a concise summary of the DataFrame\n",
    "dataframe.info(verbose=True, memory_usage='deep', ...)\n",
    "```\n",
    "\n",
    "  * **`verbose`**: If `True`, prints the full summary. If `False` (for DataFrames with many columns), it prints a short summary.\n",
    "      * **Default:** `True`\n",
    "  * **`memory_usage`**:\n",
    "      * **Default:** `'auto'` or `True` (gives a memory estimate).\n",
    "      * **When to use:** Use `memory_usage='deep'` to get the *true* total memory, which is slower but much more accurate for columns with text (`object`).\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "# Generates descriptive statistics\n",
    "dataframe.describe(percentiles=None, include=None, exclude=None)\n",
    "```\n",
    "\n",
    "  * **`percentiles`**: A list of percentile values (between 0 and 1) to show.\n",
    "      * **Default:** `[.25, .5, .75]` (shows 25th, 50th/median, 75th percentiles).\n",
    "      * **When to use:** Use `percentiles=[.1, .5, .9]` to see the 10th, 50th, and 90th percentiles.\n",
    "  * **`include`**: A list of data types to *include* in the summary.\n",
    "      * **Default:** `None` (which means *only* numeric columns).\n",
    "      * **When to use:** Use `include='object'` to summarize text columns (gives `unique`, `top`, `freq`). Use `include='all'` to show *all* columns.\n",
    "  * **`exclude`**: A list of data types to *exclude*.\n",
    "      * **Default:** `None`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 1\\. Basic Example\n",
    "\n",
    "Let's create a simple DataFrame and run all 8 commands to see what they do.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Clara', 'David'],\n",
    "    'Age': [25, 30, 22, 35],\n",
    "    'Score': [88.5, 92.0, 78.5, 85.0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"--- The DataFrame ---\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\n--- 1. .shape (Attribute) ---\")\n",
    "print(df.shape)\n",
    "\n",
    "print(\"\\n--- 2. .index (Attribute) ---\")\n",
    "print(df.index)\n",
    "\n",
    "print(\"\\n--- 3. .columns (Attribute) ---\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\n--- 4. .dtypes (Attribute) ---\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n--- 5. .head(2) (Method) ---\")\n",
    "print(df.head(2))\n",
    "\n",
    "print(\"\\n--- 6. .tail(2) (Method) ---\")\n",
    "print(df.tail(2))\n",
    "\n",
    "print(\"\\n--- 7. .info() (Method) ---\")\n",
    "# .info() prints directly, it doesn't return anything\n",
    "df.info()\n",
    "\n",
    "print(\"\\n--- 8. .describe() (Method) ---\")\n",
    "print(df.describe())\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- The DataFrame ---\n",
    "    Name  Age  Score\n",
    "0  Alice   25   88.5\n",
    "1    Bob   30   92.0\n",
    "2  Clara   22   78.5\n",
    "3  David   35   85.0\n",
    "\n",
    "--- 1. .shape (Attribute) ---\n",
    "(4, 3)\n",
    "\n",
    "--- 2. .index (Attribute) ---\n",
    "RangeIndex(start=0, stop=4, step=1)\n",
    "\n",
    "--- 3. .columns (Attribute) ---\n",
    "Index(['Name', 'Age', 'Score'], dtype='object')\n",
    "\n",
    "--- 4. .dtypes (Attribute) ---\n",
    "Name      object\n",
    "Age        int64\n",
    "Score    float64\n",
    "dtype: object\n",
    "\n",
    "--- 5. .head(2) (Method) ---\n",
    "    Name  Age  Score\n",
    "0  Alice   25   88.5\n",
    "1    Bob   30   92.0\n",
    "\n",
    "--- 6. .tail(2) (Method) ---\n",
    "    Name  Age  Score\n",
    "2  Clara   22   78.5\n",
    "3  David   35   85.0\n",
    "\n",
    "--- 7. .info() (Method) ---\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 4 entries, 0 to 3\n",
    "Data columns (total 3 columns):\n",
    " #   Column  Non-Null Count  Dtype  \n",
    "---  ------  --------------  -----  \n",
    " 0   Name    4 non-null      object \n",
    " 1   Age     4 non-null      int64  \n",
    " 2   Score   4 non-null      float64\n",
    "dtypes: float64(1), int64(1), object(1)\n",
    "memory usage: 224.0+ bytes\n",
    "\n",
    "--- 8. .describe() (Method) ---\n",
    "             Age      Score\n",
    "count   4.000000   4.000000\n",
    "mean   28.000000  86.000000\n",
    "std     5.830952   5.700877\n",
    "min    22.000000  78.500000\n",
    "25%    24.250000  83.375000\n",
    "50%    27.500000  86.750000\n",
    "75%    31.250000  89.375000\n",
    "max    35.000000  92.000000\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "  * **`.shape`**: Told us it's 4 rows, 3 columns.\n",
    "  * **`.index`**: Showed the row labels are a `RangeIndex` (0 to 3).\n",
    "  * **`.columns`**: Showed the column labels (`Name`, `Age`, `Score`).\n",
    "  * **`.dtypes`**: Showed the type of each column (`object` is text).\n",
    "  * **`.head(2)`**: Showed just the first 2 rows.\n",
    "  * **`.tail(2)`**: Showed just the last 2 rows.\n",
    "  * **`.info()`**: This is the best summary. It shows the index, columns, `Non-Null Count` (no missing data\\!), and `Dtype` for *every column*.\n",
    "  * **`.describe()`**: Gave us statistical summaries (count, mean, min, max, etc.) for the *numeric columns only* (`Age` and `Score`).\n",
    "\n",
    "-----\n",
    "\n",
    "### 2\\. Intermediate Example\n",
    "\n",
    "Now, let's use a \"messier\" dataset with missing values and mixed types to see how `.info()` and `.describe()` *really* shine.\n",
    "\n",
    "**Example 9: `.info()` to find missing data**\n",
    "\n",
    "```python\n",
    "data_messy = {\n",
    "    'Name': ['Alice', 'Bob', 'Clara', 'David', 'Eva'],\n",
    "    'Age': [25, 30, np.nan, 35, 28], # One missing Age\n",
    "    'City': ['NY', 'LA', 'NY', 'SF', 'LA']\n",
    "}\n",
    "df_messy = pd.DataFrame(data_messy)\n",
    "\n",
    "print(\"--- Messy DataFrame ---\")\n",
    "print(df_messy)\n",
    "\n",
    "print(\"\\n--- .info() reveals the NaN ---\")\n",
    "df_messy.info()\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- Messy DataFrame ---\n",
    "    Name   Age City\n",
    "0  Alice  25.0   NY\n",
    "1    Bob  30.0   LA\n",
    "2  Clara   NaN   NY\n",
    "3  David  35.0   SF\n",
    "4    Eva  28.0   LA\n",
    "\n",
    "--- .info() reveals the NaN ---\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 5 entries, 0 to 4\n",
    "Data columns (total 3 columns):\n",
    " #   Column  Non-Null Count  Dtype  \n",
    "---  ------  --------------  -----  \n",
    " 0   Name    5 non-null      object \n",
    " 1   Age     4 non-null      float64\n",
    " 2   City    5 non-null      object \n",
    "dtypes: float64(1), object(2)\n",
    "memory usage: 248.0+ bytes\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "Look at the `.info()` output. The `RangeIndex` shows **5 entries**. The `Age` column shows **4 non-null**. This mismatch (5 vs. 4) instantly tells you that the `Age` column has *one missing value*. Also, note that the `Age` `Dtype` is `float64`. This is because `NaN` is a float, so it \"upcast\" the whole column from integer to float to hold the missing value.\n",
    "\n",
    "**Example 10: `.describe()` on numeric vs. object columns**\n",
    "\n",
    "```python\n",
    "# Using the same messy DataFrame\n",
    "print(\"--- .describe() (Default, numeric) ---\")\n",
    "print(df_messy.describe())\n",
    "\n",
    "print(\"\\n--- .describe(include='object') (Text) ---\")\n",
    "print(df_messy.describe(include='object'))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- .describe() (Default, numeric) ---\n",
    "             Age\n",
    "count   4.000000\n",
    "mean   29.500000\n",
    "std     4.203173\n",
    "min    25.000000\n",
    "25%    27.250000\n",
    "50%    29.000000\n",
    "75%    31.250000\n",
    "max    35.000000\n",
    "\n",
    "--- .describe(include='object') (Text) ---\n",
    "        Name City\n",
    "count      5    5\n",
    "unique     5    3\n",
    "top    Alice   NY\n",
    "freq       1    2\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "  * The default `.describe()` only showed the `Age` column (the only numeric one).\n",
    "  * By specifying `include='object'`, we get a *different* summary for the `Name` and `City` columns.\n",
    "      * **count**: Total non-null entries.\n",
    "      * **unique**: Number of unique values (`LA`, `NY`, `SF` = 3 unique cities).\n",
    "      * **top**: The most frequent value (`NY`).\n",
    "      * **freq**: How many times the `top` value appeared (2).\n",
    "\n",
    "-----\n",
    "\n",
    "### 3\\. Advanced or Tricky Case\n",
    "\n",
    "**Example 11: `.describe(include='all')`**\n",
    "\n",
    "This parameter combines *both* summaries, showing `NaN` for stats that don't apply.\n",
    "\n",
    "```python\n",
    "# Using the same messy DataFrame\n",
    "print(\"--- .describe(include='all') ---\")\n",
    "print(df_messy.describe(include='all'))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- .describe(include='all') ---\n",
    "        Name        Age City\n",
    "count      5   4.000000    5\n",
    "unique     5        NaN    3\n",
    "top    Alice        NaN   NY\n",
    "freq       1        NaN    2\n",
    "mean     NaN  29.500000  NaN\n",
    "std      NaN   4.203173  NaN\n",
    "min      NaN  25.000000  NaN\n",
    "25%      NaN  27.250000  NaN\n",
    "50%      NaN  29.000000  NaN\n",
    "75%      NaN  31.250000  NaN\n",
    "max      NaN  35.000000  NaN\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "This is tricky but very thorough. For the `Name` and `City` columns, it shows the text stats (`unique`, `top`, `freq`) and `NaN` for the numeric stats (`mean`, `std`, etc.). For the `Age` column, it does the reverse.\n",
    "\n",
    "**Example 12: `.info(memory_usage='deep')`**\n",
    "\n",
    "This is an advanced trick to find the *real* memory usage. `object` columns (text) are tricky because Pandas just stores *pointers* to the text. `memory_usage='deep'` tells `.info()` to go and measure the *actual size of the text*, which can be much, much larger.\n",
    "\n",
    "```python\n",
    "print(\"\\n--- .info() (Normal) ---\")\n",
    "df_messy.info()\n",
    "\n",
    "print(\"\\n--- .info(memory_usage='deep') (Accurate) ---\")\n",
    "df_messy.info(memory_usage='deep')\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "--- .info() (Normal) ---\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 5 entries, 0 to 4\n",
    "...\n",
    "memory usage: 248.0 bytes\n",
    "\n",
    "--- .info(memory_usage='deep') (Accurate) ---\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 5 entries, 0 to 4\n",
    "...\n",
    "memory usage: 604.0 bytes\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "The normal `.info()` reported 248.0 bytes. But the `deep` scan showed 604.0 bytes. This is because it went and *actually measured* the size of the strings ('Alice', 'Bob', 'NY', 'LA', etc.). On a dataset with millions of rows, this difference could be megabytes vs. gigabytes.\n",
    "\n",
    "-----\n",
    "\n",
    "### 4\\. Real-World Use Case\n",
    "\n",
    "This is the **\"Initial Data Triage\"** workflow you will do 100% of the time after loading data.\n",
    "\n",
    "**Scenario:** You just loaded a huge file: `df = pd.read_csv('sales_data_2025.csv')`\n",
    "\n",
    "Your workflow should be:\n",
    "\n",
    "**Example 13: The 5-Step Triage**\n",
    "\n",
    "1.  **`df.info()`**\n",
    "\n",
    "      * **Action:** Run it.\n",
    "      * **Questions to ask:** \"How many entries? 2.1M\". \"Are there any nulls?\" (e.g., \"Oh, `customer_email` has 1.8M non-null... lots missing\\!\"). \"Are the `Dtypes` correct?\" (e.g., \"Wait, `Order_Date` is `object`? I need to convert that to datetime. `Revenue` is `object`? That's bad.\")\n",
    "\n",
    "2.  **`df.head()`**\n",
    "\n",
    "      * **Action:** Run it.\n",
    "      * **Questions to ask:** \"What does the data *look* like?\" (e.g., \"Ah, `Revenue` is `object` because it has '$' and ',' in it, like '$1,200.50'. I'll need to clean that.\")\n",
    "\n",
    "3.  **`df.shape`**\n",
    "\n",
    "      * **Action:** Check it.\n",
    "      * **Questions to ask:** \"How many rows and columns? 2.1M rows, 45 columns.\"\n",
    "\n",
    "4.  **`df.describe()`**\n",
    "\n",
    "      * **Action:** Run it.\n",
    "      * **Questions to ask:** \"Are there any *sanity* issues?\" (e.g., \"Look at `Quantity`: `min` is -10. That's a data error.\"). \"Look at `Unit_Price`: `max` is 99,000. Is that real or an outlier?\"\n",
    "\n",
    "5.  **`df.describe(include='object')`**\n",
    "\n",
    "      * **Action:** Run it.\n",
    "      * **Questions to ask:** \"How many unique categories?\" (e.g., \"Column `Country`: `unique` is 250. Good.\"). (e.g., \"Column `State`: `unique` is 75... wait, there are only 50 states. That means I have dirty data like 'NY' and 'New York' and 'n.y.'\")\n",
    "\n",
    "**Explanation:**\n",
    "This 5-step process, which takes 30 seconds, gives you a complete \"to-do\" list for your data cleaning.\n",
    "\n",
    "-----\n",
    "\n",
    "### 5\\. Common Mistakes / Pitfalls\n",
    "\n",
    "**Mistake 14: Attribute vs. Method (`.shape` vs `.shape()`)**\n",
    "\n",
    "```python\n",
    "# Wrong code\n",
    "try:\n",
    "    print(df.shape())\n",
    "except TypeError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    \n",
    "# Correct code\n",
    "print(f\"Correct: {df.shape}\")\n",
    "```\n",
    "\n",
    "**Error/Wrong Output:**\n",
    "\n",
    "```\n",
    "Error: 'tuple' object is not callable\n",
    "Correct: (5, 3)\n",
    "```\n",
    "\n",
    "**Why it happens:**\n",
    "`.shape` is an **attribute** (a property), not a method (an action). You don't add `()` to it. The same is true for `.index`, `.columns`, and `.dtypes`.\n",
    "\n",
    "**Mistake 15: Method vs. Attribute (`.info()` vs `.info`)**\n",
    "\n",
    "```python\n",
    "# Wrong code\n",
    "print(df.info)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "<bound method DataFrame.info of     Name   Age City\n",
    "0  Alice  25.0   NY\n",
    "1    Bob  30.0   LA\n",
    "2  Clara   NaN   NY\n",
    "3  David  35.0   SF\n",
    "4    Eva  28.0   LA>\n",
    "```\n",
    "\n",
    "**Why it happens:**\n",
    "This is the reverse mistake. `.info()` is a **method** (an action), so it *requires* `()` to be called. Without them, you just get a description of the method itself, which isn't useful.\n",
    "**Correction:** `df.info()`\n",
    "\n",
    "-----\n",
    "\n",
    "### 6\\. Key Terms (Explained Simply)\n",
    "\n",
    "  * **Attribute:** A stored property of an object (e.g., `df.shape`). Accessed *without* `()`.\n",
    "  * **Method:** An action or function an object can perform (e.g., `df.head()`). Accessed *with* `()`.\n",
    "  * **Metadata:** Data *about* your data (e.g., number of rows, column names, data types).\n",
    "  * **Descriptive Statistics:** Summaries of your data (e.g., mean, median, min, max).\n",
    "  * **`dtype` (Data Type):** The type of data in a column (`int64` for numbers, `float64` for decimals, `object` for text).\n",
    "  * **`NaN` (Not a Number):** Pandas' marker for a single missing value.\n",
    "  * **Percentile/Quartile:** A measure of where data falls. The 25th percentile (or 1st quartile) means 25% of the data is *below* that value. The 50th percentile is the `median`.\n",
    "\n",
    "-----\n",
    "\n",
    "### 7\\. Best Practices\n",
    "\n",
    "  * **Always use these first:** Make it a reflex. `pd.read_csv(...)`, then `df.info()`, `df.head()`.\n",
    "  * **Trust `.info()` for missing data:** It's the fastest way to check *all* columns at once.\n",
    "  * **Check `dtypes` obsessively:** A column `Revenue` being `object` is a 100% guarantee of future errors. Fix it *first*.\n",
    "  * **Use `df.describe(include='object')`:** Don't just `describe` your numbers. Your text columns often have just as many data quality issues (like typos, which you'd see in the `unique` count).\n",
    "  * **Don't trust `.head()`:** `.head()` only shows the first 5 rows. They might be perfectly clean, while row 50,000 is a mess. It's a *peek*, not a *proof*.\n",
    "\n",
    "-----\n",
    "\n",
    "### 8\\. Mini Summary\n",
    "\n",
    "  * These 8 tools are for **inspection**, not modification.\n",
    "  * **Attributes (no `()`)**:\n",
    "      * `.shape`: (rows, cols)\n",
    "      * `.index`: Row labels\n",
    "      * `.columns`: Column labels\n",
    "      * `.dtypes`: Data type of each column\n",
    "  * **Methods (with `()`)**:\n",
    "      * `.head()`/`.tail()`: Peek at first/last 5 rows.\n",
    "      * `.info()`: Best summary for `NaN`s and `dtypes`.\n",
    "      * `.describe()`: Statistical summary for numeric (default) or text (`include='object'`) columns.\n",
    "\n",
    "-----\n",
    "\n",
    "### 10\\. Practice Tasks\n",
    "\n",
    "**Data for Tasks:**\n",
    "\n",
    "```python\n",
    "data = {\n",
    "    'Category': ['A', 'B', 'A', 'A', 'B', 'C'],\n",
    "    'Value': [10, 15, 12, np.nan, 8, 10],\n",
    "    'Notes': ['good', 'bad', 'ok', 'good', 'ok', 'bad']\n",
    "}\n",
    "df_practice = pd.DataFrame(data, index=['r1', 'r2', 'r3', 'r4', 'r5', 'r6'])\n",
    "```\n",
    "\n",
    "**Task 16 (Easy):**\n",
    "Using `df_practice`, print its shape and its column names.\n",
    "\n",
    "**Task 17 (Medium):**\n",
    "Print a summary of `df_practice` that shows you that the 'Value' column has a missing entry. Then, print the first 3 rows.\n",
    "\n",
    "**Task 18 (Hard):**\n",
    "Generate *two* summaries from `df_practice`:\n",
    "\n",
    "1.  A statistical summary of the 'Value' column.\n",
    "2.  A frequency summary of the 'Category' and 'Notes' columns.\n",
    "\n",
    "-----\n",
    "\n",
    "### 11\\. Recommended Next Topic\n",
    "\n",
    "You've now created a DataFrame and \"explored\" it to find problems. [cite\\_start]The next logical step in the roadmap is to start *fixing* those problems by changing the DataFrame's structure (like renaming or dropping columns). [cite: 97-100]\n",
    "\n",
    "**Recommended:** **Structure changes (Renaming: `.rename()`, Adding/removing columns: `.insert()`, `del`, `.drop()`)**\n",
    "\n",
    "-----\n",
    "\n",
    "### 12\\. Quick Reference Card\n",
    "\n",
    "| Command | Type | What It Shows |\n",
    "| :--- | :--- | :--- |\n",
    "| **`.shape`** | Attribute | `(rows, columns)` tuple. |\n",
    "| **`.index`** | Attribute | The row labels. |\n",
    "| **`.columns`** | Attribute | The column labels. |\n",
    "| **`.dtypes`** | Attribute | `Series` of data types for each column. |\n",
    "| **`.head(n=5)`** | Method | `DataFrame` of the *first* `n` rows. |\n",
    "| **`.tail(n=5)`** | Method | `DataFrame` of the *last* `n` rows. |\n",
    "| **`.info()`** | Method | Complete summary of index, columns, `NaN` counts, `dtypes`, and memory. |\n",
    "| **`.describe()`** | Method | `DataFrame` with statistics (mean, std, min, max, quartiles) for numeric columns. |\n",
    "| `.describe(include='object')` | Method | `DataFrame` with stats (count, unique, top, freq) for text columns. |\n",
    "\n",
    "-----\n",
    "\n",
    "### 13\\. Common Interview Questions\n",
    "\n",
    "1.  **You've just loaded a 2GB CSV. What are the *first* 3-5 things you do?**\n",
    "      * `df.info()`: To check for nulls and `dtypes`.\n",
    "      * `df.head()`: To visually inspect the data and see *why* a `dtype` might be wrong (e.g., '$' in a number).\n",
    "      * `df.shape`: To confirm the size.\n",
    "      * `df.describe()`: To check for outliers or data errors (e.g., `min = -1`).\n",
    "2.  **How do you check for missing values in a DataFrame?**\n",
    "      * The best and fastest way is `df.info()`. It gives you a `Non-Null Count` for every column at once.\n",
    "      * (A more advanced way is `df.isna().sum()`, which gives a direct count of `NaN`s per column).\n",
    "3.  **How do you get a summary of text-based (non-numeric) columns?**\n",
    "      * You use `df.describe(include='object')`. This will show you the `count`, `unique` values, the `top` (most frequent) value, and its `freq` (frequency).\n",
    "4.  **What is the difference between `df.shape` and `df.shape()`?**\n",
    "      * `df.shape` is an **attribute** that returns a tuple (rows, columns). This is correct.\n",
    "      * `df.shape()` is an **error**. You are trying to *call* the tuple as a function.\n",
    "\n",
    "-----\n",
    "\n",
    "### 14\\. Performance Considerations\n",
    "\n",
    "  * **O(1) (Instant):**\n",
    "      * `.shape`, `.index`, `.columns`, `.dtypes`. These are properties, just looking them up.\n",
    "  * **O(k) (Very Fast):**\n",
    "      * `.head(k)`, `.tail(k)`. Time is proportional to `k`, not the size of the DataFrame.\n",
    "  * **O(N\\*M) or O(N) (Can be slow):**\n",
    "      * `.info()`: Can be slow if `verbose=True` (the default) on a DataFrame with *many columns* (M). It has to iterate over all columns.\n",
    "      * `.describe()`: Must iterate over all *numeric* columns (M\\_numeric) and all rows (N) to compute statistics. Time is roughly O(N \\* M\\_numeric).\n",
    "      * `.info(memory_usage='deep')`: This is the slowest, as it has to iterate over *every single text element* in all `object` columns. Use it, but be aware it can take time.\n",
    "  * **Memory:** All these methods are very light on memory. They return small new objects (summaries), not copies of your full data.\n",
    "\n",
    "-----\n",
    "\n",
    "### 15\\. When NOT to Use This\n",
    "\n",
    "  * **Don't use these to *change* data.** These are for *inspection only*.\n",
    "  * **Don't use `.head()` to make assumptions.** Do not assume your whole 10-million-row dataset is clean just because the first 5 rows are.\n",
    "  * **Don't use `.describe()` as your only statistical analysis.** It is a *summary*. It will not show you if your data has two different groups (bimodal distribution) or other complex patterns. It's a *starting point* for analysis, not the end.\n",
    "  * **Don't use `.info()` for a precise `NaN` count in a script.** `df.info()` *prints* to the console. If you need to *use* the number of `NaN`s in a variable, use `df.isna().sum()` (which returns a Series) instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3aecc-a4e6-49eb-9360-849ac12e7607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
